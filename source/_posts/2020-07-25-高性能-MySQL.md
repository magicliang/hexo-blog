---
title: 高性能 MySQL
date: 2020-07-25 09:57:21
tags:
- 高性能
- MySQL
---
# 译者序

MySQL 最初是放在 LAMP 里一起讨论。

淘宝网最初使用 LAMP 架构，使用 MySQL 4.0。03 年底改用 IOE，从 08 年开始又筹划去 IOE。09 年的时候 MySQL 的架构也从垂直拆分改成水平拆分。2012 年 MySQL 的单库已经有了 6.5 万的 QPS。

本书是 mysqlperformanceblog.com 的几个专家（同样也是 percona 的创始人）的作品，对于 InnoDB/XtraDB 等存储引擎的性能优化和诊断方法有很深入和详细的介绍。

# 推荐序

作者在性能优化领域工作多年，这本书诞生于 MySQL 还没有什么可扩展性和可测量性的时代，直到现在这些方面已经有了长足的进步。说到合理的方法，他们简直把这件事当成了科学，**首先定义需要解决的问题，然后通过合理的猜测和精确的测量来解决问题**。

性能优化 = 定义问题 + 猜测 + 测量

要关注：

 - 吞吐量
 - 响应时间

吞吐量 = 线程数/响应时间

追求新技能，如排队理论对性能的影响。

# MySQL 的架构和历史

MySQL 能够应用的场景：

 - 嵌入到应用程序中
 - 数据仓库
 - 内容索引
 - 部署软件
 - 高可用的冗余系统
 - 在线事务处理系统

MySQL 最重要、最与众不同的特性是它的存储引擎架构，这种设计将查询处理（Query Processing）及其他系统任务（Server Task）和数据的存储/提取相分离。

## MySQL 的逻辑架构

第一层：client + connector。连接处理、授权认证、安全等等。
第二层：Server。职责是：实现函数、查询解析、缓存、优化，所有的跨存储引擎的功能都在这一层实现，包括存储过程、触发器、视图。
第三层：storage engine。实现数据的存储和提取。每个引擎都互有优势（pros）和劣势（cons）。server 和 storage engine 之间通过统一的**接口 API 进行通信**。存储引擎层不解析 SQL。

### 连接管理和安全性

（在 Server 层）每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个 CPU 核心或者 CPU 中运行。服务器会缓存线程，不必为每个新建的连接创建和销毁线程（**常见的设计模式，要考虑伸缩性，和线程池的分层**）。MySQL 还支持 SSL 连接，所以具有使用 X.509 认证的能力。

Server 层有自己的 privilege 模型。

### 优化与执行

MySQL 会解析查询，并创建内部数据结构（AST），然后对其进行各种优化，包括：

- 重写查询
- 决定表的读写顺序
- 选择合适的索引

用户可以通过特殊的关键字提示器（hint），影响它的决策过程，也可以通过解释器（explain）来理解 server 是怎样决策的。

用户可以优化：

 - 查询
  - 优化索引
  - 优化其他查询条件
  - 优化翻页
  - 优化排序
 - schema
 - 配置

进而使应用可以高效运行。

优化器并不关心使用什么存储引擎，但存储引擎会影响优化器。优化器会询问存储引擎一些统计信息，包括但不局限于存储容量、具体操作的开销信息、表的统计信息，进行一些类似 cost-based 的优化。

对于 select 语句，在**解析查询以前**，Server 层会先检查查询缓存（Query Cache），如果能够找到对应的查询，则不再进入 parser、optimizer 和 execution 的全过程。**这要求 server 层能够很好地控制 cache 的 consistency**。

## 并发控制（Concurrency Control）

理论上只要有多个查询（**事务或者事务里的语句**）在同一时刻修改数据，都会产生并发控制问题（另一种的 Race Condition）。

邮箱的例子：邮件如果是单链表，并发访问可能导致数据结构的分叉。所以基本的方案必须通过加锁来维护数据结构的正确性（也就是业务的正确性）。然而加锁的方案只是基础方案，不是一个高性能方案。**高性能方案应该是混合使用 lock 和 lock-free 的方案**。

### 读写锁

读通常没有问题，但通常的业务逻辑总是读写混合的。所以锁系统应该提供差异化的读锁（share lock）和写锁（exclusive lock）。

读锁相互共享。
写锁相互阻塞。

### 锁力度

**尽量只锁定需要修改的部分数据 - 只对修改的数据片进行精确的锁定**，是在并发力度下性能最优的锁定策略，可以尽量避免锁冲突（lock contest）。

锁本身也需要资源，这部分的性能开销往往为人所忽略。

在存储引擎的设计中，锁管理是个非常重要的决定。将锁固定在某个级别，可以为某个应用场景提供更好的性能，但同时会支持对另外一些应用场景的良好的支持。

最容易被忽略也最常见的表锁的使用场景，Alter Table - 所以需要 online ddl 工具的支持。

**server 层可以自己实现表锁，存储引擎层也可以实现表锁。server 层的表锁可以直接忽略存储引擎层的表锁。**

### 行级锁

行级锁可以最大程度地支持并发处理（同时也带来了最大的**锁开销**）。

只有存储引擎层可以实现行级锁。

## 事务

在理解事务以前，接触数据库的其他高级特性言之尚早。

事务就是一组原子性的 SQL 查询，或者一个独立的工作单元。事务其实是所有 statement 的组。

银行的模型，saving 和 checking，需要三个步骤：

1. 检查支票账户的余额高于 200 美元。
2. 从支票账户的余额中减去 200 美元。
3. 在储蓄账户的余额中加入 200 美元。

```SQL
-- 等同于 BEGIN
START TRANSACTION;
// 业务逻辑
COMMIT;
```

ACID 的标准定义：

### 原子性

一个事务必须被视为一个不可分割的最小工作单元。

### 一致性

数据库总是从一个一致性的状态，转换到另外一个一致性的状态。

### 隔离性

事务的修改在最终提交以前，对其他事务是不可见的。

### 持久性

一旦事务提交，则修改可以被永久保存到数据库中。即使系统崩溃，变更后的数据也不会丢失。

事务的出现使存储引擎对资源消耗变大了，因为支持事务则流程会变复杂。用户可以选择使用事务的存储引擎，也可以选择不使用事务的存储引擎（不支持事务也支持 LOCK TABLES 等操作，一样可以进行并发控制）。

### 隔离级别

#### 可读未提交

大多数情况下，无益处（虽然性能最好）。

#### 可读已提交

一个事务开始时，只能看见已提交的事务所做的修改。
这个级别又叫不可重复读（nonrepetable read）。

#### 可重复读

每个事务从头到尾都能得到 consistency read。但因为不能防止 phantom row 所以不能防止 phantom read。

#### 可串行化

强制事务串行执行，每一行都加了锁（最起码每个 select 隐式地成为 select in share mode）。

### 死锁

InnoDB 可以自动检测死锁，也可以自动处理死锁-将持有最少的 row x lock 的事务进行回滚。

避免死锁的方法是避免数据冲突。

### 事务日志

WAL 就是事务日志，通常是追加写。

写完事务日志以后，buffer pool 里的 dirty pages 会通过 fsync 之类的操作写进磁盘里。

### MySQL 中的事务

支持事务的存储引擎有：

 - InnoDB
 - NDB Cluster
 - XtraDB
 - PBXT
 
#### 自动提交（autocommit）模式

MySQL 默认会设置 autocommit 为 1。autocommit 对 InnoDB 生效，对 MyISAM 不生效（相当于 autocommit 总是为 1）。

大批量操作数据的命令（如 ALTER 类的 DDL 语句），会强制操作对事务的修改提交。

#### 在事务中混合使用存储引擎

**同一个事务可以跨表操作。**

表可以由不同的存储引擎存储。

**混合使用事务性和非事务性的存储引擎会导致事务无法回滚。**

所以表要显式地指定存储引擎。

#### 隐式锁定和显式锁定

insert、delete、update 会隐式地锁定表里的记录。但 MySQL 支持如下的显式锁：

 - select ... lock in share mode（非 SQL 标准）
 - select ... for update（非 SQL 标准）
 - LOCK TABLES（server 层）
 - UNLOCK TABLES（server 层）

## （InnoDB 中的）MVCC 

包括 MySQL、PostgreSQL、Oracle 都实现了 MVCC，但各自的实现机制不一样，因为 MVCC 没有统一的标准（没有人能说其他实现是错的）。

可以认为 MVCC 是行级锁的一个变种，但大多数情况下 MVCC 代表着无锁操作。

MVCC 为每行保存了两个隐藏列，一行保存行的创建时间（创建事务版本），一行保存行的删除时间（删除事务版本）。这里说的时间，实际上指的是系统版本号（system number version）。每个事务开始的时候，会取当前事务的版本号，作为事务自己的版本。

### SELECT

 - InnoDB 只查找版本早于当前版本的数据行（行的系统版本号小于或等于事务的系统版本号），这样读到的数据，要么在数据开始以前就已经存在，要么是本事务创造的（如果这是一个长事务，则之前已经 insert 过很多带有本 transaction version 的行了）。
 - 行的删除版本未定义，或者大于当前版本号，这样可以保证事务读到的行，在事务开始以前未被删除

### Insert

为每插入的每一行保存当前系统版本号作为行含本号。

### DELETE

InnoDB 为删除的每一行保存当前系统版本号作为行删除标识。

### UPDATE

插入新的一行，保存当前系统版本作为行版本号。保存当前系统版本号到原来的行作为删除标识。

大多数操作都可以不用加锁，只能读取到符合标准的行。RU 总是读取到最新行，Serialize 总是对每个读取的行加锁。

## MySQL 的存储引擎

在文件系统中，MySQL 将每个数据库（也可以称之为 schema）保存为数据目录下的一个子目录。创建表时，MySQL 会在数据库子目录下创建一个表同名的.frm 文件，保存表的定义。

存储引擎使用操作系统中的目录和文件保存了库和表的定义。在 windows 操作系统中，定义是大小写不敏感的；在 unix 操作系统中，大小写是敏感的。

### InnoDB 存储引擎

InnoDB 是默认的事务型存储引擎（transactional storage engine），也是最重要、使用最广泛的存储引擎。它被设计成用来处理大量的 short-lived 事务，短期事务大部分情况是正常提交的，很少会被回滚。InnoDB 也适用于非事务性存储。

#### InnoDB 的历史

InnoDB 有着复杂的发展历史，最初有旧的 innodb 存储引擎，但最终 Oracle 旗下的 InnoDB 公司提供的 InnoDB plugin 在当前版本原生编译时就成为当代的 InnoDB 引擎。近期的版本主要改进集中在可测量性、可扩展性、可配置化、性能、各种新特性和对 Windows 的支持上。

#### InnoDB 概览

InnoDB 的数据存放在表空间（table space）中，表空间是由 InnoDb 管理的一个黑盒子，由一系列数据文件组成。InnoDB 将表的数据和索引存放在单独的文件中（合一）。

InnoDB 的表基于聚簇索引建立（EveryThing is an Index in InnoDB），因此 InnoDB 的索引结构和其他存储引擎有很大不同，聚簇索引对主键查询有很高的性能。不过它的二级索引中必须包含主键列，所以主键列很大的话，其他的所有索引都会很大。因此，表上的索引较多的话，主键应该尽可能小。

### MyISAM 存储引擎

MyISAM 无事务，崩溃后无法恢复。因为它无事务的特性，所以很多人都一直认为 MySQL 无事务。在无事务的时代，用户依然可以使用 LOCK TABLES 和 UNLOCK TABLES 来进行并发控制。

#### 存储

**MyISAM 将索引和数据文件分开存储**。MyISAM 中的表可以分为 dynamic row 和 fixed row。

#### MyISAM 特性

靠加锁来支持并发。

需要修复表（不是什么好特性）。

（即使对 BLOB 和 TEXT）支持全文索引 + 复杂查询。

Delayed Key Write，对索引的更新是延迟的，所以一旦发生 crash，数据会丢失，又需要修复表（所以不是什么好特性）。

MyISAM 支持对行级进行压缩的压缩表。压缩表可以极大地提高性能，但数据出问题还是要修复。

MyISAM 最典型的性能问题是表锁的问题。

### 其他存储引擎

 - Archive
 - Blackhoe
 - Csv
 - Federated
 - Memory
 - Merge
 - NDB 它让 MySQL 引入了 share nothing 的架构

### 第三方存储引擎

#### OLTP 类存储引擎

Percona 的 XTRDB 是基于 InnoDB 的一个改进版本。XtraDB 可以作为InnoDB 的一个完全的替代产品。

PBXT 支持引擎级别的复制，外键约束，对 SSD 的支持较好，被 MariaDB 所包含。

TokuDB 使用一种新的叫作分形树（fractal trees）的索引数据结构。TokuDB 是缓存无关的，因此即使其大小超过内存性能也不会下降，也就没有内存生命周期和碎片的问题。TokuDB 是种大数据存储引擎，因为其拥有很高的压缩比，可以在很大的数据量上创建大量索引。

RethinkDB 最初是为 SSD 设计的，和 PBXT 差不多。

### 选择合适的存储引擎

除非必须使用 InnoDB 不具备的特性而不能妥协，否则应该使用 InnoDB。

实际上，OLTP 的场景下使用 InnoDB，OLAP 场景，使用大数据框架来分析，已经成为了大多数互联网公司的标配场景。

不要轻易认定“MyISAM 比 InnoDB”之类的经验之谈。在很多已知场景下，InnoDB 的速度是 MyISAM 望尘莫及的，特别是能够使用聚簇索引查询，或者所访问的数据都可以放入内存中的应用。

### 转换表的存储引擎

#### ALTER TABLE

```SQL
ALTER TABLE mytable ENGINE = InnoDB;
```

这个操作会执行很长时间，MySQL 会把原表复制到新表中（这种新表被重新组织过，可以消除空洞）。在复制的过程中会消耗系统所有的 I/O 能力，而且表上会加读锁（**变成了 READ ONLY 的表，算是一种半停机的设置**）。

如果转换表的存储引擎，将会失去和原引擎相关的所有特性。一张表切换两次不同的引擎，可能导致外键都丢失。

#### EXPORT 和 IMPORT

可以使用 mysqldump 把表导出，然后修改 CREATE TABLE 的 engine 选项，注意同时修改表名，因为同一个 db 里不能存在相同的表名。

#### CREATE 和 SELECT

```SQL
CREATE TABLE innodb_table LIKE myisam_table;
ALTER TABLE innodb_table ENGINE=innodb;
INSERT INTO innodb_table SELECT * FROM myisam_table;
```

如果数据量不大的话，这样做很好；否则需要考虑分批处理，因为这样会产生过多的 undo。

可以考虑使用 Percona Toolkit 提供的 pt-online-schema-change 的工具。

## MySQL Timeline

5.5 版本的 MySQL 是史上质量最高的版本。体现了 Oracle 收购了 MySQL AB 以后对产品的关注。

## 总结

虽然有很多不同的插件 API，但存储引擎 API 还是最重要的。如果能理解 MySQL 在存储引擎和服务层之间处理查询时如何通过 API 来回交互，就能抓住 MySQL 基础架构的精髓。

**对 InnoDB 而言，一切操作都是事务。**

Oracle 一开始收购了 InnoDB，而后收购了 MySQL，最终导致了两者的融合。

# MySQl 基准测试

基准测试（benchmark）是 MySQL 新手和专家都需要掌握的一项基本技能。简单地说，基准测试是针对系统设计的一种压力测试。本章讲讨论基准测试的重要性、策略和工具。我们将特别讨论一下 sysbench，这是一款非常优秀的 MySQL 基准测试工具。

## 为什么要做基准测试

基准测试是唯一有效的、可以学习系统在给定的工作负载下会发生什么的方法。

基准测试的问题是这不是真实压力的测试，真实压力不可预期而且变化多端。测试工具的局限会影响结果的有效性。

使用基准测试对容量的余量进行规划，也不能简单地把基准测试里得到的 tps 增长看作容量的增长。

## 基准测试的策略

对系统进行测试，即 full-stack。单独测试 MySQL，即 single-component。
尽量做 full-stack 测试，因为：
- 用户关注的是整个应用的性能
- MySQL 并非总是应用的瓶颈，如何揭示瓶颈？
- 只有对应用做整体测试，才能发现各部分之间的缓存带来的影响。
- 正义应用的继承测试更真实

尽量使用生产真实数据的拷贝。

### 测试何种指标

#### 吞吐量（throughput）

单位时间能够处理的事务数，是最重要的需要关注指标。

#### 响应时间（response time）

因为应用本身的响应时间本身是受各种因素影响而波动的，所以大部分情况下关注 top percentile 90 之类的指标即可。可以用图表来关注这些指标。

#### 并发性（concurrency）

MySQL 的并发性不同于应用的并发性。应用的并发性通常指可以同时存在多少个会话，MySQL 的高并发则关注到底可以同时存在多少个数据库连接。很多时候并发性测试并不是寻找某个指标，而是看特定的并发性的前提下（如 128 个 server 线程），到底能够达到多大的 tps 和 rt。

#### 可扩展性（scalability）

在业务压力变化的情况下，可以测量增大系统的业务压力（或者提供更好的软硬件配置），吞吐量是不是也能线性增加（即是不是可以直接 scale up）。

大部分系统通常不能线性增加性能。

## 基准测试方法

应该避免一些常见的错误：

 - 使用真实数据的子集而不是全集。
 - 使用错误的数据分布。
 - 使用不真实的分布参数。
 - 在多用户的场景中，只做单用户的测试。
 - 在单服务器上测试分布式应用-同样地，不要用单线程来测试多线程应用。
 - 与真实用户行为不匹配。
 - 反复执行同一个查询。
 - 没有检查错误。
 - 忽略了系统预热。
 - 使用默认的服务器配置。
 - 测试时间太短。
 
测试要掌握业务的全貌，应该关注：
 - 注意 normal case 的分布，注意这些分布肯定不是均匀分布，所以真实的差异性流量是很必须的，这也导入了 corner case。
 - 如果流量和身份有关，则应该注意流量构成的差异。
 - 应该注意错误日志。

### 设计和规划基准测试

对于 OLTP 型业务，可以考虑 TPC-C；对于 OLAP 和即席查询的业务，可以考虑 TPC-H。

应该写下详细的测试规划，记录规划里的参数和预期的返回值。

### 基准测试应该运行多长时间

为了到系统稳定为止，应该运行尽可能长的时间。

### 获取系统的性能和状态

要定期地快速采样整个系统的性能快照（类似 JMX/top 方案，把系统的性能的涨落寻找出来）。

### 获得准确的测试结果

对 IO 密集型（IO-Bound）应用，不要采用 CPU 密集型（CPU-Bound）应用的测试标准。

确认测试结果是否重复，每次重新测试之前要确保系统的状态是否是一致。有必要的话要重启系统。

如果测试以前要改数据或者 schema，要注意用快照还原数据库。插入不同数量级的数据造成的磁盘碎片度和在磁盘上的分布肯定不同。一个确认磁盘数据的分布尽可能一致的方法是，每次都进行快速格式化并进行磁盘分区复制。

基于默认的配置进行测试通常没有意义，因为默认配置是基于消耗很少内存的极小应用的。

如果测试中出现异常数据，不要轻易地当作坏数据点进行丢弃。

### 运行基准测试并分析结果

要把“数字”变成“知识”。

### 绘图的重要性

考虑使用 gnuplot。

## 基准测试工具

### 集成测试工具

 - ab 最简单
 - http_load
 - JMeter 复杂很多，但对集成测试已经够用
 - 列表项
 
### 单组件式测试工具
 - mysqlslap 随着 MySQL 本身发布，可以根据 schema 生成 SELECT 语句，测试可以执行并发连接数，并指定 SQL 语句。
 - sql-bench 单线程测试，自带测试用例。
 - Super Smack
 - Database Test Suite
 - Percona's TPCC-MySQL Tool
 - sysbench **全功能测试工具**，它可以测试 cpu 性能（通过计算素数），磁盘 io 性能（通过模拟文件读写），db 性能（只要指定好 db 的文件夹和数据库）。

# 服务器性能剖析

测量服务器的时间花在哪里的工具是性能剖析技术。

应该抱有空杯心态，抛掉一些对性能的常见误解。

## 性能优化定义

对性能的定义有很多种，如吞吐量、响应（延迟）时间等**。原则一、性能即响应时间（Response Time）。**我们可以简单地采用一种方案来定义提升性能，就是看特定的工作负载下，降低响应（延迟 latency）时间。吞吐量比响应时间更容易测量，但测量响应时间更容易让我们的系统得到优化。

资源是用来消耗的。纯粹地降低资源的消耗不一定就能提高性能。高版本的 InnoDB 有更多的 CPU 利用率，并不是它性能变差了，可能反而性能变好了（CMS、G1 等 JVM 垃圾收集器同理）。

如果降低响应时间，得到的一个副产品就是系统的吞吐量提升了（通常，工作线程的可复性用变高了）。

**原则二、无法测量就无法有效地优化。**不要把时间花在修改东西上，应该把时间花在测量响应时间上（实际上修改东西也需要反复测试，盲目地修改等于盲目地反复测试，是一个线性复杂度的工程师时间浪费）。如果通过测量没有得到答案，那么要么测量的方式错了，要么测量得不够完整。与其把 90% 的时间花在修改系统上，不如把 90% 的时间花在测量上。

完成一项任务的时间通常可以分为两个部分：执行时间和等待时间。执行时间的优化方法，是优化子任务的执行频率、效率和并行度。等待时间的优化方法则复杂得多，需要很强的诊断工具。

测量通常是错的，例如多数的测量不是全量采样，多数的测量也只是系统的间断快照，而不是连续的快照。重点是测量有多不准确。

### 通过性能剖析进行优化

profiler 的工作方式总是相似的：在任务启动时启动计时器，在任务结束时停止计时器，然后减去不同的时间得到响应时间。

响应时间的统计结果通常包括：

 - 排名
 - 调用次数
 - （平均）响应时间
  - 执行时间
  - 等待时间
 - （有可能的话）执行结果

很多时间我们既要做基于执行时间的分析，也要坐基于等待时间的分析。但很多时候系统本身不提供很细致的内部测量点，所以我们并不能真的分析出一个响应时间内部，执行时间占多少，等待时间占多少。例如，我们并不一定知道，一个 sql 执行的时候，磁盘 io 的等待时间是多少。
   
### 理解性能剖析

只理解总计和平均值，会缺失很多信息。如：

 - 值得优化的查询（worthwhile query）：如果一个优化花了 1000 美元，却没有带来任何业务收益。其实等于做了一个 1000 美元的逆优化。
 - 异常情况：即使没有做过 profiling，也有些问题需要解决-当然如果有办法做全链路跟踪，没有 profiling 的死角的话，可以不考虑这个问题。
 - 未知的未知（unknown-unknown，拉姆斯菲尔德的笑话）：工具总有局限性，只能在一定精度内说明问题。
 - 被掩藏的细节：平均值不能说明问题。我们更多地需要直方图、百分比、标准差等等工具。
 
## 对应用程序进行剖析

**对性能的剖析建议还是自上而下进行。**这样可以追踪用户发起到服务器响应的整个流程。

性能瓶颈可能有很多影响因素：

 - 外部资源：比如调用了外部的 web 服务或者搜索引擎。
 - 应用需要大量时间处理的数据，比如分析一个超大的 xml 文件（或者查询一张超大的表并且返回结果也超大）。
 - 在循环中执行昂贵的操作，比如滥用正则表达式。
 - 使用低效的算法。
 
性能剖析会让系统变慢吗？局部来看，会。因为性能剖析总有开销（例如，Visual Studio 构建出的程序有 debug 的版本和 release 版本，debug 的版本里带有测量点，因此更慢一些）。全局来看，不会，因为性能剖析最终会让我们设计出更快的程序。

好的监控工具应该可以全天候测量应用程序的性能（在任何时间、任何环境）。

MySQL 企业监控器可以提供查询的性能。通常这类工具不是在库里实现（如美团的 zebra 里的内部打点），就是在代理层实现（如架设一个 MySQL proxy，当然这本书的作者不建议这样做）。

## 剖析 MySQL 查询

### 剖析服务器查询

服务器端的剖析很有价值，因为在服务器端可以有效地审计效率低下的查询。

如果只是需要找出代价高的查询，可以使用慢查询日志（尽管 MySQL 提供了很多的的测量点）。

当代的 workbench 可以很方便地查看某个 server 的 status，间接地提供 profiling 的功能。

#### 捕获 MySQL 的查询到日志文件中

MySQL 的慢查询的日志精度最高、开销最低。性能开销可以忽略不计，但对硬盘的大小有要求，这要求我们打开 log rotation 工具。

MySQL 同样支持通用查询日志（general query log），但对性能剖析没有什么时机作用。

如果因为某些原因，无法在服务器上记录查询（也就是看不到慢查询日志），那么还有两种替代方案：

 - SHOW FULL PROCESSLIST。查看慢查询、慢事务，进而 kill 查询、kill 事务。可以考虑使用 pt-query-digest。
 - 通过 tcp 抓包，然后解析。可以考虑使用 tcp-dum + pt-query-digest。
 
### 分析单条查询

三种方法，show status、show profile 和检查慢查询日志的条目。

#### show profile

```bash
-- 全局开启性能剖析
set profiling = 1
-- 查看各个查询的性能剖析
show profiles
```

show profiles 其实是一种查表的方案。

#### show status

show status 其实是显示一组计数器，既包括全局级别（global）的计数器，也包括会话级别（session）的计数器。

读懂这些计数器，需要读懂 innodb 的数据结构。

show status 其实也是一种查表的方案。

#### 使用慢查询日志

我们使用 explain 得到的结果是评估出来的查询性能结果。而使用慢查询日志得到的是实际执行的查询情况，可以很方便地读到实际的查询结果。explain 无法解释系统发生抖动，而 slow query 却可以。

使用特殊的工具，如 pt-query-digest，可以把它转化为查表的形式。

#### 使用 performance schema

另一种正在快速开发中，代表未来发展方向的性能剖析方案。

还是一种查表的形式。

### 使用性能剖析

server profiling 和 query profiling 可能都可以给性能优化提供帮助。用户需要对服务器如何执行查询有较深的了解。剖析报告应该尽可能多地收集需要的信息，给出诊断问题的正确方向。

但也有很多时候我们无法得到可靠的优化建议，因为：

- 我们可能只关注了 server profiling 而忽略了query profiling。
- 我们可能测量的只是查询开始之前的计数器，而不是查询开售的数据。
- 可能备份正在执行
- 可能发生了某种类型的 lock contention 或者其他争用。

## 诊断间歇性问题

幻影问题，往往难以重现，而且需要观察几个月。乱枪打鸟式的乱试，或者随机修改服务器配置来试图侥幸地找到问题，是人之常情，却也是危险的。试错不仅浪费时间，而且可能有可能让问题变得更坏。

### 单条查询问题还是服务器问题

服务有整体变慢吗，还是只有单条查询变慢？

服务器的问题非常常见，特别是老版本的 MySQL 既不适合 SMP 服务器，又有一定的扩展性限制。通常升级新版本的 MySQL 可以解决如上问题，但一旦出现问题，需要对新版本的更复杂机制有所了解。

如何判断是单挑查询问题还是服务器问题？如果问题周期性地出现，那么可以在某次活动中观察到（比较常见），或者整页运行脚本收集数据，第二天来分析结果。

此外，还有三种常见技术：

#### 使用 SHOW GLOBAL STATUS

最好每秒执行一次，列出类似查表的数据，然后使用 awk 工具截取变化的变量，形成类似 jstat log之类的分段涨落数据。

#### 使用 SHOW PROCESSLIST

最好也可以频繁执行，列出类似查表的数据，它对线程、连接的统计有很好的效应。

如果 MySQL 版本较新，可以查询 INFORMATION_SCHEMA 的 PROCESSLIST表；或者使用 innotop 工具以较高频率刷新。

#### 使用查询日志（query log）

如果有必要，打开 long_query_time = 0 的标记，记录所有的查询。但这个配置需要重置所有连接才能全局生效（除非使用 percona 的版本，可以强制在不断开连接的前提下，自动刷新配置）。

### 捕获诊断数据

如何尽可能多地收集数据，而不是恰好搜集到问题出现时的数据（特别是很容易收集不到）？

我们至少需要：

1. 一个可靠而且实时的“触发器”，也就是能区分什么时候问题出现的方法。
2. 一个收集诊断数据的工具。

#### 诊断触发器

#### 需要收集什么样的数据


在 GNU/Linux 平台，可以考虑 oprofile、strace、tcpdump。如果MySQL 内部线程卡在一个地方很长时间，往往都有相同的堆栈跟踪信息。这时候可以先启动 gdb，然后 attach 到 mysqld 进程，将所有线程的堆栈都转储（dump）出来。可以使用`sort | uniq | sort`等命令来排序出总计最多的堆栈信息。

#### 解释结果数据

这一节细节太多，还是要读原文为准。

## 其他剖析工具

### 使用 USER_STATISTICS 表

如果我们执行如下语句，可以看到 MySQL Percona 的 InnoDB 内核里有一些内置表（最初由谷歌开发的）：

```
SHOW TABLES FROM INFORMATION_SCHEMA LIKE '%_STATISTICS'

CLIENT_STATISTICS
INDEX_STATISTICS
TABLE_STATISTICS
THREAD_STATISTICS
USER_STATISTICS
```

### 使用 strace

strace 是另一个可以拿来度量系统调用的时间。例子：

```
strace -cfp $(pidof mysqld)
```

## 总结

值得总结的东西还是前面提供的东西：

 - 定义性能最有效的方法是响应时间
 - 无法测量就无法优化
 - 测量的最佳开始点是应用程序，而不是数据库
 - 大多数系统无法完整地测量，测量有时候也会有错误的结果。
 - 完整的测量会产生大量需要分析的数据，所以需要用到剖析器。
 - 剖析是一种汇总信息，掩盖和丢弃了太多的细节。
 - 有两种消耗时间的操作：工作和等待。
 - 优化和提升是两回事。
 - 注意你的直觉，但应该只根据直觉来指导解决问题的思路，而不是用于确定的问题。**决策应当尽量基于数据而不是感觉**。
 
# Schema 与数据类型优化

良好的逻辑设计和物理设计是高性能的基石。反范式的设计（计数表、汇总表、索引表）可以加快某些类型的查询，也可以使另一些类型的查询变慢。比如添加计数表和汇总表是一种很好的查询优化方式。

通常，我们要做 normalization，有时候要做冗余设计。

## 选择优化的数据类型

 - 更小的通常会更好。通常更小的数据类型有更小的数据开销。
 - 简单就好。使用最适配的数据类型通常比使用某些 hacky 的数据类型要好。
 - 尽量避免 null。很多列的默认值都是 null（即使没有显式地指定 `default null`）。通常情况下指定 not null 意味着我们选择性地回避了 null 的陷阱。查询中允许为 null 的列，索引本身的结构会比较复杂，查询的结果有时候也会出现反直觉的设计。

`SHOW CREATE TABL`展示的是基本类型（的正式名称），而不是别名。

### 整数类型

整数（whole numer）包括：

- TINYINT 8 位
- SMALLINT 16 位
- MEDIUMINT 24 位
- INT 32 位
- BIGINT 64 位

整数类型有可选的 UNSIGNED 属性，表示不允许负值。有符号和无符号使用同样的存储空间，所以无符号数的取值范围更大。

### 实数类型

MySQL 支持不精确类型（ FLOAT 和 DOUBLE 浮点数，使用浮点运算进行近似计算），也支持精确类型（DECIMAL）。

浮点运算被 cpu 原生支持，所以性能更好。DECIMAL 的支持是被 MySQL 内部通过自身实现支持的。

存储财务数据时，应该尽量使用 DECIMAL 或者 BIGINT。

### 字符串类型

 VARCHAR  可以变换存储空间的长度（除非指定了 ROW_FORMAT=FIXED），所以通常会更加节省存储空间。**行总是存在数据页里面的**，varchar 如果扩容，会导致数据页分裂。CHAR 则总是定长的适合存储很短，定长或者近乎定长的字符串，如 MD5。
 
有 VARCHAR  就有 VARBINARY。二进制数据和字符串数据的区别在于字符串数据有字符集和校对规则。

### BLOB 和 TEXT 类型

BLOB 和 TEXT 在 MySQL 里单独存储为对象的。

使用 BLOB 和 TEXT 会有可能会导致磁盘临时表（disk temp table），有必要的话可以考虑内存临时表（heap temp table）。如果 EXPLAIN 执行计划的 Extra 列包含“ Using Tempory”，则说明这个查询使用了隐式临时表。

### 日期和时间类型

5.5 的 MySQL 的最小时间粒度是秒。

#### DATETIME

与时区无关，使用 8 字节存储。可以使用 ANSI 的标准时间定义格式，如“2020-01-01 00:00:00”。

#### TIMESTAMP

与时区有关，指的是 Unix 的描述（可以使用 FROM_UNIXTIME 函数转换为日期），使用 4 字节存储。

### BIT 

最好不要用，很难理解和处理

### 选择标识符

即 PK 列：
- 整数类型，整数通常是最好选择，而且可以使用 AUTO_INCREMENT。
- ENUM 和 SET 是糟糕的选择。
- 应该避免使用字符串类型，因为他们很消耗空间。MyISAM 通常使用压缩索引，这导致查询慢很多。
- 尽量少用随机字符串，如 MD5()、SHA1（）。因为这些函数生成的新值会分布在很大的空间内。这会导致一些 select 语句变得很慢，而且 INSERT 变得更慢，这会导致页分裂，磁盘随机访问。会导致缓存的局部性原理失效，因为冷热数据的空间分布太不均匀。这种方案的唯一好处是可以消除热点。

### 特殊数据类型

IP 地址类型与其用 VARCHAR，不如直接用整数存储。可以考虑用 INET_ATON() 或者 INET_NTOA()-但如果使用了 ORM 框架，这种方案反而会比较难用。

## MySQL schema 设计中的陷阱

- 太多的列：MySQL 的存储引擎 API 和 server 层之间有一个行缓冲区。太多的列会使得行缓冲区转换出关键的行消耗过多的 cpu。
- 太多的关联。EAV（实体-属性-值）是一种常见的糟糕设计模式。EAV 很容易导致自关联（self-join）。MySQL 限制关联不能超过 61 张表，最好的实践是在 12 张表里做关联。- 更好的实践是不要关联。
- 慎用枚举。增加枚举值要 alter table，会导致全表锁这样的阻塞操作。
- 慎用 set。问题和枚举差不多，而且和枚举一样会让业务代码复杂。
- 慎用 null- 但有时候用 magic number 不如 null，null 可以代表未知值。如 datetime 的“0000-00-00 00:00:00”。

## 范式和反范式

对任何给定的数据，通常都有很多种表示方法，从完全的范式化到完全的反范式化，以及两者的折中。在范式化的数据库中，每个事实数据会出现且只出现一次。相反，在反范式的数据库中，信息是冗余的，可能会存储在多个地方。

冗余会导致数据不准确-“一个人有两块表，他就永远不知道时间。”

### 范式的优点和缺点

优点：
- 通常性能更好
- 不容易有冗余引起的逻辑错误

缺点：
- 切范式会导致 join，join 可能性能不好 - 这在 ES 上表现得尤为明显。

### 反范式化的优点和缺点

如果有两张表 join 起来的成本很高，把它们合成一张宽表（用合表的方式实现 join），加上索引，可以显著提升相关的查询效率。

这个章节里举了一个例子，在同时使用 where 和 order by limit 索引，查询优化器有可能走 order by 的索引，而不是 where 的索引，这样做不是基于基势的二分查找，效率可能和全表扫描差不多。

接下来它举了一个优化的例子，把 where 和 order by 的两列写在一个联合索引里，这样不用回表就完成了查询和排序（甚至只在存储引擎层就可以这样做）。

### 混用范式和反范式

纯洁的范式和反范式只出现在实验室里（正如教学用的模式和架构只出现在课本上一样）。

最常见的反范式化数据是复制或者缓存，这些冗余的数据可以通过触发器级联更新，但更好的方案是选择不常被更新的列。很多时候为了排序的需要，我们需要把数据从一张表冗余到另一张表。

## 缓存表和汇总表

有时候提升性能最好的方法是在同一张表中保存衍生的冗余数据。然而，有时候也需要一张完全独立的汇总表或者缓存表（特别是为满足检索的需求时）。

我们指的缓存表是可以比较简单地从 schema 的其他表获取（但每次获取的速度比较慢）数据的表。

而汇总表则保存的是使用 GROUP BY 语句聚合数据的表。也有人使用术语“累积表”（Roll-Up Table）来称呼这些表。

以网站为例子。我们可以为网站准备一个计数器表，记录每个小时的发送消息数。虽然不能保证计数器 100% 精确，但比实时维护计数器精确得多。实时计算统计值总是很昂贵的操作，要么必须扫描表中的大部分数据，要么查询语句只能在某些特定的索引上才能有效运行，而这类索引一般会对 UPDATE 操作有影响。计算最活跃的用户或者最常见的“标签”是这种操作的典型例子。而缓存表则对优化搜索和检索查询语句很有效。

除此之外的优化方法还有：

 - 对缓存表使用不同的存储引擎
 - 把缓存表导入专门的搜索系统
 
在使用缓存表和汇总表时，必须决定是实时维护数据，还是定期重建-其实还要考虑是增量重建，还是全量重建，如果使用全量重建，整张表的存储碎片会少很多。

当重建汇总表和缓存表时，通常需要保证数据在操作时依然可用。这就需要通过影子表来实现，通常影子表的实现为：

```SQL
DROP TABLE IF EXISTS a_new, a_old;
CREATE TABLE a_new LIKE a;
-- 导入数据
-- 在一个事务里同时做替换，有可能触发一个长时间的阻塞操作。
RENAME TABLE a to a_old, a_new to a
```
这样 a_old 里还存留有老的数据，有问题可以很容易地进行快速回滚操作。

### 物化视图（MV - Materialized Views）

MySQL 不天然支持物化视图，SQL Server 和 Oracle 支持。MySQL 的解决方案是 Flexviews。

参考[《MySQL物化视图方案 FlexViews》][1]：

> Flexviews 是 MySQL 5.1 的存储过程解决方案，主要用来创建物化视图，支持表关联和大多数 MySQL 的聚合函数。
> 
> 物化视图 (MV - Materialized
> Views)在一个段中存储查询结果，并且能够在提交查询时将结果返回给用户，从而不再需要重新执行查询 —
> 在查询要执行几次时（这在数据仓库环境中非常常见），这是一个很大的好处。物化视图可以利用一个快速刷新机制从基础表中全部或增量刷新。

Flexviews 支持从 SQL 转换为 Flexviews 的 API 的调用，类似 MapReduce。它可以分析 binlog，增量而不是全量地分析数据。

### 计数器表

应用中经常需要计数，但在更新计数器时可能碰到并发问题。

计数器表的几种形态：

1. 只有一列的计数器表，每次更新的时候事务严格串行：`set count = count + 1`。这个语句不会有写丢失的问题，但多事务并发更新一行性能非常差。
2. 一行记录有两列，一列槽，一列计数器，每次更新的时候随机执行：`set count = count + 1 where slot = RAND() * 100`。这样可以一定程度提高性能，但查询真正的总数时，需要`select sum(count)`。
3. 可以加上日期 date 作为更高层的分区列。
4. 使表有 upsert 的能力（insert 可以用 ON DUPLICATE KEY 来来避免 integrity exception）：`INSERT INTO DAILY_HIT_COUNTER(day, slot, cnt) VALUES(CURRENT_DAY, RAND() * 100, 1) ON DUPLICATE KEY UPDATE cnt = cnt + 1`。


如果希望减少表的行数，以避免表变得太大，可以写一个周期执行的任务，合并所有的结果到 0 号槽，并且删除所有其他的槽：

```SQL
-- 这一行语句可以一个事务内汇总所有的数据
update daily_hit_counter as c
 inner join (
    -- 选择每一天的最小槽，且把 cnt 先汇总一下
    select day, sum(cnt) as cnt, min(slot) as mslot
    from daily_hit_counter
    group by day
 ) as x using day
 -- 因为上面汇总过了，所以这里清理所有槽
 -- 如果本槽等于最小槽，维持本槽的 count，否则设为 0
 set c.cnt = if(c.slot = x.mslot, x.cnt, 0),
 -- 如果本槽等于最小槽，设置本槽的槽为0，否则维持原状。
 c.slot = if(c.slot = x.mslot, 0, c.slot);
 
-- 第二个事务把非 min_slot 的数据都删掉
delete from daily_hit_counter where slot <> 0 and cnt = 0;
```

## 加快 ALTER TABLE 的速度

MySQL 的 ALTER TABLE 操作的性能对大表而言是个大问题。MySQL 执行大部分表结构操作的方法是用新的结构创建一个空表。从旧表中查出所有的数据插入新表，然后删除旧表。这样操作需要很长时间，而且很耗内存。

因此诞生了一种 online ddl 的方案。这些功能不需要在整个操作过程中锁表。

但一般而言，大部分 ALTER TABLE 操作会导致 MySQL 的服务中断（因为锁表）。

其基本思路有：

 - 在一个不提供服务的从库上执行 alter table 操作，然后和主库进行切换；
 - 影子拷贝（ghost 表），创建一张和原表无关的新表（需要考虑验证和同时插入的问题），然后在一个事务里通过重命名和删除表操作交换两张表。

大部分的改表工具是使用方法 2。

有时候直接 alter table 会导致大量的读和插入。但 alter column 会直接改 .frm 文件。

还有另一个巧妙变更 .frm 文件的方法：

 1. 创建一张有相同结构的空表，并进行锁需要的修改（例如增加 ENUM 常量）。
 2. 执行 FLUSH TABLES WITH READ LOCK。**这将会关闭所有正在使用的表，并且禁止任何表被打开**。
 3. （通过操作系统命令）交换 .frm 文件。
 4. 执行 UNLOCK TABLES 来释放第 2 步的读锁。

### 快速创建 MyISAM 索引

这个方法的中心思想是**通过排序创建索引，这样创建索引更快且更紧凑**-但现实中恐怕不会有很好的收益。

```SQL
ALTER TABLE tb DISABLE KEYS;
ALTER TABLE tb ENABLE KEYS;
```

如果有索引没有建好，可以用 REPAIR TABLE 来重建索引。

# 创建高性能的索引

索引（MySQL 中也叫作键（key））是存储引擎用于快速找到记录的一种数据结构。

## 索引基础

索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要。因为 MySQL 只能高效地使用索引的最左前缀列。

因为索引过于复杂，所以简单地使用 ORM 往往不能有效地利用索引。

### 索引的类型

在 MySQL 中，索引是在存储引擎层而不是服务器层实现的。所以不同的存储引擎实现的索引是不一样的。

#### B-Tree 索引

大多数存储引擎都支持 B-Tree 索引。但 InnoDB 使用 B+Tree 索引。

存储引擎以不同的方式使用 B-Tree 索引，性能也各有不同。MyISAM 使用前缀压缩技术使得索引更小，但 InnoDB 则按照原数据格式进行存储。再如 MyISAM 索引通过数据的物理位置引用被索引的行，而 InnoDB则根据主键引用被索引的行（寻址问题）。

B-Tree 通常意味着所有的值都是按顺序存储的，并且每一个叶子页到根的距离相同（**意味着 B-Tree 的深度对每个叶子而言是均衡的**）。

B-Tree 索引能够加快访问数据的速度，因为存储引擎不在需要进行全表扫描获取需要的数据。

B-Tree 的叶子节点都存在于逻辑页中，不同的存储引擎的逻辑页大小不一样，InnoDB 为 16k。

B-Tree 索引对索引列是顺序组织存储的，所以很适合查找范围数据（所以我们做查询也应该尽量寻找范围查询的机会）。

B-Tree 索引适用于全键值、键值范围或建前缀查找。

 - 全值匹配：全值匹配是指和索引中所有列进行匹配-索引有三列，匹配条件也有三列。
 - 匹配最左前缀：即只使用索引的第一列。
 - 匹配列前缀：只匹配某一列的值的开头部分。
 - 匹配范围值：只查找第一列的某个范围里的值。
 - 精确匹配某一列并范围匹配另一列：范围查询的列的右边的列都无法使用索引。
 - 只访问索引的查询：即覆盖索引。

因为索引树种的节点是有序的，所以如果 ORDER BY 子句满足前面列出的几种查询类型，则这个索引也可以满足对应的排序需求。
 
#### 哈希索引

哈希索引基于哈希表，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码。不同行的哈希码不一样。哈希表中存的是哈希码**（而不是实际值）**和每个数据行的指针。

只有 Memory 引擎显式支持哈希索引，而且它支持非唯一哈希索引。

哈希索引有如下缺点：

 - 只包含哈希值和行指针，所以无法触发覆盖索引。不过 memory 中寻址很快，影响不明显（访问硬盘则不然）。
 - 无法使用排序（因为既没有使用具体值，也没有按照具体值的顺序组织排列数据）
 - 不能使用部分列匹配
 - 因为没有存储实际值，所以哈希所以不支持 in、<>、<=>等操作，当然也不支持范围查询。
 
数据仓库中的“星型”schema，需要关联很多查找表，很适合使用哈希索引。

InnoDB 引擎有一个特殊的功能叫作“自适应哈希索引”（adaptive hash index）。InnoDB 注意到某些索引值被使用得非常频繁时，它会在内存中基于 B-Tree 再创建一个哈希索引。这是一个用户完全无法控制的行为。 

创建自定义哈希索引：在 B-Tree 基础上创建一个伪哈希索引。

举例，varchar 的 url 上的字符串会很长，但如果有个 url_crc 列，则直接查询 crc32 的值，性能会比直接查 url 高很多（因为索引体积小而选择性（selectivity）很高）。即：

```SQL
-- 建立 url 上的索引
select id from url where url = "www.mysql.com";
-- 删除 url 的索引，使用 url_crc32 作为索引。如果不删除 url 索引，则可能需要 force index 强迫查询优化器选择索引。
select id from url where url = "www.mysql.com" and url_crc = crc32("www.mysql.com");
```

这种伪哈希索引的缺点是，必须使用触发器维护哈希值。

如果维护伪哈希值，则不要使用 sha1 和 md5 之类的强加密函数，它们的目的是为了尽最大可能消除冲突，所以生成的字符串通常会非常长。

crc32 生成的散列值可能会产生大量冲突（因为生日北仑，出现哈希冲突的概率可能比想象中快得多），所以查询必须带上原始列值（否则如何处理相同的哈希值呢？）。一个比较适中的方案是自己实现一个简单的 64 位哈希函数-返回整数而不是字符串，可以通过对 md5 进行截断实现：`select conv(right(md5("www.mysql.com"), 16), 16, 10)`。

#### 空间索引（Spatial Index）

使用的数据结构是 R-Tree。这是一种全维度的索引，但只能使用在地理信息查询场景下。MySQL 的 GIS 相关功能并不完善（推荐 PostgreSQL 的 PostGIS）。

#### 全文索引（fulltext Index）

它的工作机制和其他所有索引都不一样。它查找中的是文本中的关键词，而不是直接比较索引的值。它不是简单的 where 匹配，而是在干类似搜索引擎的事情（被称为 match against）。

#### 其他索引类别

TokuDB 使用的其实是分形树索引（fractal trees index），它相当于 B-Tree 索引的升级版。

## 索引的优点

B-Tree 按照顺序存储数据，相关的列值会存储在一起，所以能够支持 order by 和 group by。

索引有如下优点：

 1. 索引大大减少了服务器要扫描的数据量。
 2. 索引可以帮助服务器避免排序和临时表。
 3. 索引可以将随机 I/O 变为顺序 I/O。

可以参考三星系统（three-star system）来评价一个索引是否足够好：

 1. 索引将所有的记录放在一起则得到一星。
 2. 索引的数据顺序和索引在查找中的排列顺序一致则获得二星。
 3. 如果索引中的列包含了查询中需要的全部列则获得三星。

对于小表，索引不如全表查询；对于中大型表，索引优于全表查询；对于超大表，可能要引入分区表-或者按照现在的做法，使用分表。

## 高性能的索引策略

### 独立的列

如果查询的列不是独立的，则 MySQL 就不会使用索引。“独立的列”指索引不能是表达式的一部分，也不能是函数的参数。因为表达式或者函数不能简单地应用到 B-Tree 的搜索里。所以好习惯应该是始终把索引列单独放在比较符号的一侧。

### 前缀索引和索引选择性

如果列值太长怎么办？一种解决方法是使用前文提到的伪哈希索引。

另一种方法是只索引开始的部分字符。到底索引效率多高，由可选择性决定（间接由基数决定）。

假设使用一列的全部内容的选择性为 x，则前缀索引的可选择性应该尽可能接近 x。这种比对就要求我们不断地 `select count(left(指定列,前缀长度))/count(*)`比对`select count(指定列)/count(*)`。

确定了索引长度以后，这样指定前缀索引：

```SQL
ALTER TABLE sakila.city_demo ADD KEY (city(7));
```

前缀索引和哈希索引一样，是一种不精确存储值的索引，所以不能拿来排序和分组。

**通常情况下，BLOB、TEXT 和特别长的 VARCHAR 是需要使用前缀索引的。**一个典型的的应用场景，是使用前缀索引来索引很长的 16 进制唯一 id。

某些情况下，后缀索引也是解决问题的妙招。MySQL 不支持后缀索引（即不支持 使用 RIGHT(key, 5)这类语法建 key）。但可以通过反转字符串来建索引的方法，巧妙地解决这个问题。

### 多列索引

不要为每个列创建相应的索引。有一些专家建议“应该为 where 中的所有列都加上索引”。**但这种建议是非常错误的**。这样建索引，充其量能够创建出一个一星索引。记住，好的索引和优秀的索引的查询性能可能差几个数量级。即使我们无法创建三星索引，我们也应该尽可能优化索引顺序和创建覆盖索引。

正确的做法是针对这张表的所有查询的最大公约数列建索引。

在 MySQL 在 5.0 引入了一种叫“索引合并”（index merge）的策略，一定程度上可以用表上的多个单列索引来指定的行。

大意是：

如果有一个 sql 类似`where a = 1 or b = 2`，or 的存在使得 mysql 不能直接使用索引。通常需要让用户转化为这种 union 查询：

```
where a = 1
union
-- 注意这个不等号查询
where b = 1 and a <> 1
```

但对于支持索引合并的 MySQL，使用原始的 SQL 可以使用一个钟 type 为 index_merge 的查询。

对此，本书提出了几个观点：

 - 对多个查询条件相交的查询，意味着单列查询的索引创建得很糟糕，应该尽量创造多列索引。
 - 对多个查询条件合并的查询，需要使用大量的 CPU 和内存资源来缓存、排序和合并。
 - 优化器不会把这些资源消耗计算到查询成本（cost）中，**优化器只关心随机页面读取**。**有时候这种查询还不如全表扫描，这时候还不如手动地将查询改成 union 为好**。

如果在 explain 中看到索引合并，应该好好检查一下查询和表的结构，看看是不是已经是最优策略。可以通过参数 optimizer_switch 来关闭索引合并功能。也可以使用 ignore index 提示来让优化器忽略掉某些索引。
 
更多例子可以参考[《 MySQL 优化之 index merge(索引合并) 》][2]。
 
### 选择合适的索引列顺序

正确的索引顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组需求（这种讨论通常仅限于 B-Tree 索引，因为只有它是按照顺序存储数据的）。

在一个 B-Tree 索引中，索引列的顺序意味着索引首先按照最左列排序，其次是第二列，以此类推。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的排序、分组和 DISTINCT 子句的查询需求。

有一个经验法则：将选择性最高的列放到索引最前列。但这并不适用于所有场景-**场景不同，选择可能也不同**。

通常而言，将选择性最高的列放在前面通常是很好的。但性能实际上不止和所有索引列的选择性（整体基数），也和查询条件的具体值有关，也就是和值的分布有关-这可能会导出一个局部基数的概念。

可以使用 sarg 方法：

```SQL
select sum（a=1）, sum(b=2) from tb\G
```

来确认到底对于具体的值而言，到底是 **a 更少还是 b 更少**（注意，这里看到局部基数的时候，关注的是小的结果集，而不是大的差异度）。

当然，这种依赖于具体值的查询可能对于所有查询而言是不公平的。除非我们有工具（诸如pt-query-digest）可以找出最差的查询出来优化。否则我们应该尽量基于全局基数和选择性，来设计我们的索引顺序。

这一节的基本原则归纳如下：

1. B-Tree 索引本质上是支持范围查找的数据结构。
2. 索引查询的最优场景是能够通过等值查询最快地找到组合查询条件的结果，所以整体基势高的列放在索引列的前缀搜索路径更短。
3. 但如果出现局部基势不平衡的状况的话，则需要慎重地考虑查询查询的主要场景。一个经典的例子是，基于时间和状态的查询。通常状态的基势要比时间要低，但直接将状态作为前缀，在某些场景下搜索比将时间作为前缀更快（因为特定状态的局部基势特别小）。所以这时候可能要设计两种前缀策略的索引，在不同的查询场景下单独使用。举例就是，大的范畴（sex、gender、country、status） 更适合作为索引前缀，如果有遇到不需要大范畴的查询，可以考虑`in ('M', 'F')`来使用最左前缀索引。
4. 而另一方面，像 date、age 之类经常进行范围查找的列，应该尽量放在索引的后面。

### 聚簇索引

**聚簇索引并不是一种单独的索引类型，而是一种索引组织方式。** 具体的细节依赖于特定的实现方式（在 Oracle 中，这叫 index-organized table），InnoDB 的做法是，在同一个结构中保存了 B-Tree 索引和数据行。

当有聚簇索引的时候，表的数据行实际上被放在叶子页（leaf page，对应于节点页）上。因为无法将数据行放在两个不同的地方，所以一张表只能有一个聚簇索引。

一些数据库服务器允许指定哪个列为聚簇索引，MySQL 只能使用主键作为聚簇索引（如果没有定义主键，InnoDB 会选择唯一的非空索引代替）。

聚簇索引的优点：

 - 可以把相关的数据保存在一起（因为主键相关联的数据会被存储在相近的地方），这样可以提高 IO 性能。
 - 数据访问更快，从索引到数据行的寻址求值变快了。
 - 使用覆盖索引扫描的查询可以直接使用页节点中的主键值。
 
聚簇索引的缺点：
 - 聚簇索引只能提高（磁盘）IO 密集型应用的性能。如果数据全部存在内存中，那么聚簇索引也没有什么优势了。
 - 插入速度严重依赖于插入顺序。按照主键的顺序插入是加载数据到 InnoDB 表中速度最快的方式。如果不按照主键的顺序加载数据，那么在加载完成后最好使用`OPTIMIZE TABLE`命令重新组织一下表。
 - 更新簇聚索引的代价很大，相当于强制 InnoDB 将每个被更新的行移动到新的位置。
 - 当行的主键值要求必须将这一行插入到某个已满的页中时，存储引擎会将该页分裂成两个页面来容纳该行。
 - 聚簇索引可能导致全表扫描变慢。尤其是行比较稀疏，或者由于页分裂导致数据存储不连续的时候。
 - 二级索引可能比想象中大，因为二级索引的叶子节点包含了引用行的主键列。
 - 二级索引访问需要两次索引查找，而不是一次。

#### InnoDB 和 MyISAM 的数据分布对比

MyISAM 按照插入顺序来在磁盘上存储数据。MyISAM 的索引的 B-Tree 里是不包含表数据的。MyISAM 的二级索引直接包含指向数据行的“行指针 ”。

而 InnoDB 的 B-Tree 的叶子节点包含以下内容：主键值、事务 id 、用于事务和 MVCC 的回滚指针，以及所有的剩余列（如果索引是前缀索引，则 InnoDB 还会包含剩余的信息）。而二级索引只包含了簇聚索引的主键值，而不是行指针（这样做，如果出现簇聚索引的整理，不会触发二级索引的的更新）。

#### InnoDB 表中按主键顺序插入行

如前所言，按照主键顺序插入行可以保证插入的性能最佳。但通常业务系统不能总是生成连续的顺序主键。所以可以定义一个代理键（surrogate key）（也就是我们经常提到的物理主键）。这种物理主键的数据和应用无关，最简单的方法是使用 AUTO_INCREMENT 自增列。

反过来说，大范围的随机聚簇索引对于 I/O  密集型应用是糟糕的。所以不要使用 UUID 来作为聚簇索引。这样产生的索引不仅插入时间更长，而且索引体积也更大（因为页分裂程度也变大了）。

顺序插入数据，每条记录总是在前一条记录的后面插入。当达到页的最大填充因子时（InnoDB 默认的填充因子是页大小的15/16），吓一跳记录会写入新的页中。

而非顺序的插入则有如下的缺点：

 1. 如果要修改的页已经从缓存中刷盘到硬盘上，需要从磁盘上读取目标页到内存中，这将导致大量的随机 I/O。
 2. 如果产生了页分裂，一次插入需要修改三个页而不是一个页。
 3. 页的数据可能变得稀疏，导致数据页有碎片。

顺序插入的唯一缺点是：

 1. 高并发的插入可能引发对 AUTO_INCREMENT_LOCK 的争用。

这个章节给我们的启示是，同样的一批数据，在 InnoDB 中完全可能成为不同的数据结构。最优的数据结构需要使用 optimize table 来获得。
  
### 覆盖索引

如果使用包含所有需要查询的字段的值，我们称之为“覆盖索引”。

覆盖索引的好处是：

 1. 覆盖索引的条目（entry）小于数据的行（row）。扫描这种数据结构的访问量极小，对缓存的负载很重要。既不需要太多的内存，也不需要做太多的数据拷贝。
 2. 簇聚索引通常要回表，而覆盖索引减少了这种回表，减少了一次随机磁盘 I/O。


覆盖索引必须存储索引列的真实值。而哈希索引、空间索引和全文索引都不存储索引列的值。实际上只有 B-Tree 索引支持覆盖索引。

EXPLAIN 得到的列里面有“Using index”字样，则意味着覆盖索引生效。

如果索引能够覆盖 where，但覆盖不了 select，则 MySQL 会回表取所有的数据行（即使这一行本来不符合 where 条件，应该先在 index 查询时被过滤掉，这造成了实际上的随机I/O）。这个问题加重了 server 层的负担，只有依靠 index condition pushdown 来解决。

查询条件使用 * 无法使用覆盖索引，解决方案是延迟关联（deffered join）：

```SQL
-- 覆盖索引里要带有 id（事实上二级索引里总是含有物理主键的值，这里的 id 其实特指业务主键）
select * from tb1 join (select id from tb1 where 覆盖索引查询条件) tb2 on tb1.id = tb2.id
```

有了 ICP （Index Condition Pushdown）这一重大改进以后，很多上面提到的优化技巧可能不再需要了。

### 使用索引扫描来做排序

MySQL 有两种方式可以生成有序的结果：

1. 通过排序操作-Order By；
2. 或者按照索引顺序扫描；如果 EXPLAIN 出来的 type 列的值为“index”，则说明 MySQL 使用了索引扫描来做排序。

能够满足索引扫描，又能排序的索引是最好的。

Order By 子句和查找性查询的限制是一样的：需要满足索引的最左前缀的要求；否则，MySQL 都需要执行排序操作，而无法利用索引排序。但有一种例外，如果 WHERE 子句或者 JOIN 子句中对这些列指定了常量，就可以“弥补”索引的不足。

如果使用多列索引，排序的时候多列的查找方向必须一致-因为索引排序的方向已经一致了。

### 压缩（前缀压缩）索引

对于 MyISAM 而言，前缀压缩索引的工作方式是：

1. 如果第一行出现了列值 perform，将其压缩为 7。

2. 第二行出现了列值 performance，将其压缩为 7,ance。

压缩索引实际值并没有被直接存储，所以无法使用二分查找，总是必须使用正向全表扫描，所以对 DESC 的排序不友好。

### 冗余和重复索引

重复索引是指在相同的列上按照相同的顺序创建的相同类型的索引。应该避免这样创建索引。

MySQL 的唯一限制和主键限制，都是通过索引实现的。

应该尽量扩展已有的索引，而不是创建新索引。如已有一个 (A) 索引，可以直接扩展为 (A, B) 索引。

因为二级索引的叶子节点包含了主键值，所以在列 (A) 上的索引就相当于 (A, ID)。而且这里的 ID 基本上可以当作一个最左前缀索引使用。 

### 未使用的索引

未使用的索引应该删除-保持唯一约束的索引除外。

### 索引和锁

索引可以让查询锁定更少的行。InnoDB 只有在访问行时才对其加锁，而索引能够减少 InnoDB 访问的行数，从而你减少锁的数量。

 具体工作原理是：
 
 1. 如果能够在存储引擎层过滤掉不需要的行-即 where 的语句全部能够由索引做判断，则只锁定结果行（对 select 和 update 皆如此）。
 2. 如果不能过滤掉相关的行，则 server 层会锁定相关的行。在早期版本的 MySQL 里，2PL 的加锁会导致整个事务结束才释放无用的行；**但 5.1 以后的 对 MySQL 5.1 及以后的版本而言，只要一过滤掉该行，该行的锁定就会被释放**。
 
一般而言，如果 EXPALIN 的结果出现了 Using where，需要考虑多出来的锁定行。

## 索引案例学习

### 支持多种查询条件

经典的索引设计应该是(sex, country, region, city, age)。

范围查询应该放在索引的最后。

如果有查询不能遵循最左索引的匹配原则，则考虑使用 in ('m', 'f') 来触发最左匹配。

对于范围条件查询，MySQL 无法再使用范围列后面的索引列了；但使用 in 则没有这个限制。但 in 会导致大量的查询条件笛卡尔积出现，过多的查询条件笛卡尔积会让 MySQL 进行查询优化时消耗大量的内存，甚至会放弃 index dive。

### 避免多个查询条件

应该尽量紧凑地使用 in 来优化复杂的查询，但对多个范围查询就很难处理了。

### 优化排序

对于`sex = 'M' Order by rating limit 10;`，创建(sex, rating)的索引，可以加速排序-换言之，查询条件和 order by的最左匹配可以搭配使用（rating 不需要在索引的最左前缀，只要它的最左前缀在 where 里被使用了就行了）。

防止翻页的方法另一个方法是用翻页来做内查询，只查出覆盖索引包含的主键值，然后再用覆盖索引的主键值来来进行外循环的查询。

## 维护索引和表

### 找到并修复损坏的表

最简单的修复表的方法是`ALTET TABLE`。

大部分让表损坏的操作，都是直接操作数据库文件的操作。单一的查询语句很难让 MySQL 损坏。

### 更新索引统计信息

MySQL 的查询优化器通过两个 API 来了解存储引擎的索引值的分部信息，以决定如何使用索引：records_in_range()，不精确；info()，精确。

MySQL 使用基于成本的模型，而衡量成本的一个主要指标是评估需要扫描多少行。

MySQL 的统计信息可以自动更新。一旦关闭自动更新，需要定期地使用 ANALYZE TABLE 来手动更新。

### 减少索引和数据的碎片

还是使用`alter table`。

## 总结

尽量寻找三星的索引：

 - 一星索引的含义是通过聚簇索引减少回表。
 - 二星索引的含义是通过索引排序来减少查询排序。
 - 三星索引的含义是用覆盖索引来减少回表。

# 查询性能优化

查询优化、索引优化、库表优化需要齐头并进，一个不落。

在优化查询的同时，我们也要学习如何为高效的查询设计表和索引。

## 为什么查询速度会慢

因为：
1. 子任务太慢
2. 子任务执行的次数太多

MySQL 从客户端到服务端再到存储引擎的步骤非常多。

## 慢查询基础：优化数据访问

查询性能优化的基本原因是查询的数据太多。

### 是否向数据库请求了不需要的数据

不需要的数据包括不需要的行，和不需要的列。

一些典型案例：

 1. 查询不必要的记录：使用 JDBC 查询全部的数据，只查询前面几条，就关闭结果集。这种情况需要使用 limit 优化。
 2. 多表关联时返回所有列：多表关联时应该使使用明确的表别名查询明确的列，而不应该直接查 *。否则会消耗大量无意义的内存、cpu 来处理这些结果列。
 3. 总是取出全部列：这样就无法使用覆盖索引。有些人为了代码片段的易用性而坚持这样做。
 4. 重复查询相同的数据：不断重复执行相同的查询，然后每次都返回完全相同的数据-这时候应该使用缓存。

### MySQL 是否在扫描额外的记录

在确定查询只返回需要的数据以后，接下来应该看看查询为了返回结果是否扫描了过多的数据。

对于 MySQL，最简单的衡量查询开销的三个指标如下：

 - 响应时间
 - 扫描的行数
 - 返回的行数

#### 响应时间

响应时间 = 服务时间 + 排队时间

很多时候，排队时间很难以说明。但排队时间往往说明了服务的争用。

#### 扫描的行数和返回的行数

理想的情况下，扫描的行数和返回的行数应该是一样的。

#### 扫描的行数和访问类型

访问类型指的是：索引扫描、范围扫描、唯一索引查询、常数引用等。

rows 是 MySQL **预估要访问的数据行数**。

我们应该尽量让扫描的行数等于返回的行数。

使用 where 有三重境界：

1. 索引自己能够在存储引擎层过滤。
2. 索引能够触发覆盖索引，where 剩下的部分在 server 层执行完，无需回表再查询数据。
3. （依靠索引）从数据表中返回（大部分的候选）数据，然后依靠 where 剩下的条件，过滤掉不符合条件的数据，这导致了大量的回表。

优化查询的三种基本思路是：

 - 使用覆盖索引
 - 改变库表结构，如使用汇总表、计数表、索引表
 - 修改复杂的查询

## 重构查询的方式

### 一个查询还是多个查询

如果逻辑上有必要的话，不要畏惧把一个查询拆分成多个查询，现代的 MySQL 服务器的物理性能能够支撑大量的查询。这样就不是把所有的工作都交给数据库来做，而是由应用程序来承担一部分繁重的工作。

### 切分查询

要对大查询分而治之，其实就是把大的执行流程拆分成小的执行流程。这样会产生小事务，小的事务日志，不会引起大面积的锁，也不会触发很大的主从延迟。

一个简单的例子是尽量分批删除数据（一万行是一个很好的颗粒度），而且最好能够在事务和事物之间进行`select sleep(1)`之类的操作。

### 分解关联查询

**分解关联查询可能是日常工作中最常用的技巧，其精髓在于使用 server 端的 in memory join 来代替 optimizer 的 join，这种 join 的灵活性更高。**通常我们禁止直接在 MySQL 底层使用 join，server 端的 in memory join 成为了自然而然的替代品。

很多高性能的应用都会对关联查询进行分解。简单地，可以（每一次只）对每一个表进行单表查询，然后将结果在应用程序中进行关联。我们可以在一个 SQL 里对三张表进行大 join：

```SQL
SELECT FROM tag
    JOIN tag_post on tag.id = tag_post.tag_id
    JOIN post on tag_post.post_id = post.id
WHERE tag.tag = 'mysql';
```

可以写成三个查询，从 tag 查起，然后查 tag_post，然后查 post。
这样查有几个好处：

- 让缓存的效率更高。复杂的查询更稀有，而原子查询通常更容易被缓存（特别是热数据）。
- 将查询分解后，执行单个查询可以减少锁竞争-每个 statement 是一个单独的事务，锁的颗粒度变小了，持有锁的时间长度也变少了。
- 在应用层做关联，可以更容易对数据库做拆分。
- 查询本身的效率也会变高-通常单一的 JOIN ON 不如使用 in（）这种有跑徐的顺序查询效率高。
- 可以减少冗余记录。MySQL 的 nested loop join 本身可能会使内层循环重复访问一些数据。
- 更进一步，这样做其实在应用层实现了 hash join，在某些场景这比 nested loop join 效率高得多。

## 查询执行的基础

![MySQL的执行路径.png](MySQL的执行路径.png)

1. 客户端发送一条查询给服务器。
2. 服务器先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。
3. 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划。
4. MySQL根据优化器生成的执行计划，调用存储引擎的API执行查询。
5. 返回结果给客户端。

### MySQL 客户端/服务器端通信协议

MySQL 的客户端和服务器端的通信协议是“半双工”的。这类似一个抛球游戏，只有拿到球的一方可以把球抛出去。

客户端使用一个单独的数据包将查询传给服务器。

服务器给用户的数据则由多个数据包组成。客户端必须接收完整的数据包（而不能自己选择读取多少即终止），服务器端往客户端**推**数据。

多数连接 MySQL 的库函数，都会把所有的数据缓存在内存中（MySQL 必须等到所有的数据都发完才能释放自己的资源），还可以逐行获取需要的数据。




```SQL
```


  [1]: https://www.oschina.net/p/flexviews/
  [2]: https://www.cnblogs.com/digdeep/p/4975977.html
