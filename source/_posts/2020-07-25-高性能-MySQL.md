---
title: 高性能 MySQL
date: 2020-07-25 09:57:21
tags:
- 高性能
- MySQL
---
# 译者序

MySQL 最初是放在 LAMP 里一起讨论。

淘宝网最初使用 LAMP 架构，使用 MySQL 4.0。03 年底改用 IOE，从 08 年开始又筹划去 IOE。09 年的时候 MySQL 的架构也从垂直拆分改成水平拆分。2012 年 MySQL 的单库已经有了 6.5 万的 QPS。

本书是 mysqlperformanceblog.com 的几个专家（同样也是 percona 的创始人）的作品，对于 InnoDB/XtraDB 等存储引擎的性能优化和诊断方法有很深入和详细的介绍。

# 推荐序

作者在性能优化领域工作多年，这本书诞生于 MySQL 还没有什么可扩展性和可测量性的时代，直到现在这些方面已经有了长足的进步。说到合理的方法，他们简直把这件事当成了科学，**首先定义需要解决的问题，然后通过合理的猜测和精确的测量来解决问题**。

性能优化 = 定义问题 + 猜测 + 测量

要关注：

 - 吞吐量
 - 响应时间

吞吐量 = 线程数/响应时间

追求新技能，如排队理论对性能的影响。

# MySQL 的架构和历史

MySQL 能够应用的场景：

 - 嵌入到应用程序中
 - 数据仓库
 - 内容索引
 - 部署软件
 - 高可用的冗余系统
 - 在线事务处理系统

MySQL 最重要、最与众不同的特性是它的存储引擎架构，这种设计将查询处理（Query Processing）及其他系统任务（Server Task）和数据的存储/提取相分离。

## MySQL 的逻辑架构

第一层：client + connector。连接处理、授权认证、安全等等。
第二层：Server。职责是：实现函数、查询解析、缓存、优化，所有的跨存储引擎的功能都在这一层实现，包括存储过程、触发器、视图。
第三层：storage engine。实现数据的存储和提取。每个引擎都互有优势（pros）和劣势（cons）。server 和 storage engine 之间通过统一的**接口 API 进行通信**。存储引擎层不解析 SQL。

### 连接管理和安全性

（在 Server 层）每个客户端连接都会在服务器进程中拥有一个线程，这个连接的查询只会在这个单独的线程中执行，该线程只能轮流在某个 CPU 核心或者 CPU 中运行。服务器会缓存线程，不必为每个新建的连接创建和销毁线程（**常见的设计模式，要考虑伸缩性，和线程池的分层**）。MySQL 还支持 SSL 连接，所以具有使用 X.509 认证的能力。

Server 层有自己的 privilege 模型。

### 优化与执行

MySQL 会解析查询，并创建内部数据结构（AST），然后对其进行各种优化，包括：

- 重写查询
- 决定表的读写顺序
- 选择合适的索引

用户可以通过特殊的关键字提示器（hint），影响它的决策过程，也可以通过解释器（explain）来理解 server 是怎样决策的。

用户可以优化：

 - 查询
  - 优化索引
  - 优化其他查询条件
  - 优化翻页
  - 优化排序
 - schema
 - 配置

进而使应用可以高效运行。

优化器并不关心使用什么存储引擎，但存储引擎会影响优化器。优化器会询问存储引擎一些统计信息，包括但不局限于存储容量、具体操作的开销信息、表的统计信息，进行一些类似 cost-based 的优化。

对于 select 语句，在**解析查询以前**，Server 层会先检查查询缓存（Query Cache），如果能够找到对应的查询，则不再进入 parser、optimizer 和 execution 的全过程。**这要求 server 层能够很好地控制 cache 的 consistency**。

## 并发控制（Concurrency Control）

理论上只要有多个查询（**事务或者事务里的语句**）在同一时刻修改数据，都会产生并发控制问题（另一种的 Race Condition）。

邮箱的例子：邮件如果是单链表，并发访问可能导致数据结构的分叉。所以基本的方案必须通过加锁来维护数据结构的正确性（也就是业务的正确性）。然而加锁的方案只是基础方案，不是一个高性能方案。**高性能方案应该是混合使用 lock 和 lock-free 的方案**。

### 读写锁

读通常没有问题，但通常的业务逻辑总是读写混合的。所以锁系统应该提供差异化的读锁（share lock）和写锁（exclusive lock）。

读锁相互共享。
写锁相互阻塞。

### 锁力度

**尽量只锁定需要修改的部分数据 - 只对修改的数据片进行精确的锁定**，是在并发力度下性能最优的锁定策略，可以尽量避免锁冲突（lock contest）。

锁本身也需要资源，这部分的性能开销往往为人所忽略。

在存储引擎的设计中，锁管理是个非常重要的决定。将锁固定在某个级别，可以为某个应用场景提供更好的性能，但同时会支持对另外一些应用场景的良好的支持。

最容易被忽略也最常见的表锁的使用场景，Alter Table - 所以需要 online ddl 工具的支持。

**server 层可以自己实现表锁，存储引擎层也可以实现表锁。server 层的表锁可以直接忽略存储引擎层的表锁。**

### 行级锁

行级锁可以最大程度地支持并发处理（同时也带来了最大的**锁开销**）。

只有存储引擎层可以实现行级锁。

## 事务

在理解事务以前，接触数据库的其他高级特性言之尚早。

事务就是一组原子性的 SQL 查询，或者一个独立的工作单元。事务其实是所有 statement 的组。

银行的模型，saving 和 checking，需要三个步骤：

1. 检查支票账户的余额高于 200 美元。
2. 从支票账户的余额中减去 200 美元。
3. 在储蓄账户的余额中加入 200 美元。

```SQL
-- 等同于 BEGIN
START TRANSACTION;
// 业务逻辑
COMMIT;
```

ACID 的标准定义：

### 原子性

一个事务必须被视为一个不可分割的最小工作单元。

### 一致性

数据库总是从一个一致性的状态，转换到另外一个一致性的状态。

### 隔离性

事务的修改在最终提交以前，对其他事务是不可见的。

### 持久性

一旦事务提交，则修改可以被永久保存到数据库中。即使系统崩溃，变更后的数据也不会丢失。

事务的出现使存储引擎对资源消耗变大了，因为支持事务则流程会变复杂。用户可以选择使用事务的存储引擎，也可以选择不使用事务的存储引擎（不支持事务也支持 LOCK TABLES 等操作，一样可以进行并发控制）。

### 隔离级别

#### 可读未提交

大多数情况下，无益处（虽然性能最好）。

#### 可读已提交

一个事务开始时，只能看见已提交的事务所做的修改。
这个级别又叫不可重复读（nonrepetable read）。

#### 可重复读

每个事务从头到尾都能得到 consistency read。但因为不能防止 phantom row 所以不能防止 phantom read。

#### 可串行化

强制事务串行执行，每一行都加了锁（最起码每个 select 隐式地成为 select in share mode）。

### 死锁

InnoDB 可以自动检测死锁，也可以自动处理死锁-将持有最少的 row x lock 的事务进行回滚。

避免死锁的方法是避免数据冲突。

### 事务日志

WAL 就是事务日志，通常是追加写。

写完事务日志以后，buffer pool 里的 dirty pages 会通过 fsync 之类的操作写进磁盘里。

### MySQL 中的事务

支持事务的存储引擎有：

 - InnoDB
 - NDB Cluster
 - XtraDB
 - PBXT
 
#### 自动提交（autocommit）模式

MySQL 默认会设置 autocommit 为 1。autocommit 对 InnoDB 生效，对 MyISAM 不生效（相当于 autocommit 总是为 1）。

大批量操作数据的命令（如 ALTER 类的 DDL 语句），会强制操作对事务的修改提交。

#### 在事务中混合使用存储引擎

**同一个事务可以跨表操作。**

表可以由不同的存储引擎存储。

**混合使用事务性和非事务性的存储引擎会导致事务无法回滚。**

所以表要显式地指定存储引擎。

#### 隐式锁定和显式锁定

insert、delete、update 会隐式地锁定表里的记录。但 MySQL 支持如下的显式锁：

 - select ... lock in share mode（非 SQL 标准）
 - select ... for update（非 SQL 标准）
 - LOCK TABLES（server 层）
 - UNLOCK TABLES（server 层）

## （InnoDB 中的）MVCC 

包括 MySQL、PostgreSQL、Oracle 都实现了 MVCC，但各自的实现机制不一样，因为 MVCC 没有统一的标准（没有人能说其他实现是错的）。

可以认为 MVCC 是行级锁的一个变种，但大多数情况下 MVCC 代表着无锁操作。

MVCC 为每行保存了两个隐藏列，一行保存行的创建时间（创建事务版本），一行保存行的删除时间（删除事务版本）。这里说的时间，实际上指的是系统版本号（system number version）。每个事务开始的时候，会取当前事务的版本号，作为事务自己的版本。

### SELECT

 - InnoDB 只查找版本早于当前版本的数据行（行的系统版本号小于或等于事务的系统版本号），这样读到的数据，要么在数据开始以前就已经存在，要么是本事务创造的（如果这是一个长事务，则之前已经 insert 过很多带有本 transaction version 的行了）。
 - 行的删除版本未定义，或者大于当前版本号，这样可以保证事务读到的行，在事务开始以前未被删除

### Insert

为每插入的每一行保存当前系统版本号作为行含本号。

### DELETE

InnoDB 为删除的每一行保存当前系统版本号作为行删除标识。

### UPDATE

插入新的一行，保存当前系统版本作为行版本号。保存当前系统版本号到原来的行作为删除标识。

大多数操作都可以不用加锁，只能读取到符合标准的行。RU 总是读取到最新行，Serialize 总是对每个读取的行加锁。

## MySQL 的存储引擎

在文件系统中，MySQL 将每个数据库（也可以称之为 schema）保存为数据目录下的一个子目录。创建表时，MySQL 会在数据库子目录下创建一个表同名的.frm 文件，保存表的定义。

存储引擎使用操作系统中的目录和文件保存了库和表的定义。在 windows 操作系统中，定义是大小写不敏感的；在 unix 操作系统中，大小写是敏感的。

### InnoDB 存储引擎

InnoDB 是默认的事务型存储引擎（transactional storage engine），也是最重要、使用最广泛的存储引擎。它被设计成用来处理大量的 short-lived 事务，短期事务大部分情况是正常提交的，很少会被回滚。InnoDB 也适用于非事务性存储。

#### InnoDB 的历史

InnoDB 有着复杂的发展历史，最初有旧的 innodb 存储引擎，但最终 Oracle 旗下的 InnoDB 公司提供的 InnoDB plugin 在当前版本原生编译时就成为当代的 InnoDB 引擎。近期的版本主要改进集中在可测量性、可扩展性、可配置化、性能、各种新特性和对 Windows 的支持上。

#### InnoDB 概览

InnoDB 的数据存放在表空间（table space）中，表空间是由 InnoDb 管理的一个黑盒子，由一系列数据文件组成。InnoDB 将表的数据和索引存放在单独的文件中（合一）。

InnoDB 的表基于聚簇索引建立（EveryThing is an Index in InnoDB），因此 InnoDB 的索引结构和其他存储引擎有很大不同，聚簇索引对主键查询有很高的性能。不过它的二级索引中必须包含主键列，所以主键列很大的话，其他的所有索引都会很大。因此，表上的索引较多的话，主键应该尽可能小。

### MyISAM 存储引擎

MyISAM 无事务，崩溃后无法恢复。因为它无事务的特性，所以很多人都一直认为 MySQL 无事务。在无事务的时代，用户依然可以使用 LOCK TABLES 和 UNLOCK TABLES 来进行并发控制。

#### 存储

**MyISAM 将索引和数据文件分开存储**。MyISAM 中的表可以分为 dynamic row 和 fixed row。

#### MyISAM 特性

靠加锁来支持并发。

需要修复表（不是什么好特性）。

（即使对 BLOB 和 TEXT）支持全文索引 + 复杂查询。

Delayed Key Write，对索引的更新是延迟的，所以一旦发生 crash，数据会丢失，又需要修复表（所以不是什么好特性）。

MyISAM 支持对行级进行压缩的压缩表。压缩表可以极大地提高性能，但数据出问题还是要修复。

MyISAM 最典型的性能问题是表锁的问题。

### 其他存储引擎

 - Archive
 - Blackhoe
 - Csv
 - Federated
 - Memory
 - Merge
 - NDB 它让 MySQL 引入了 share nothing 的架构

### 第三方存储引擎

#### OLTP 类存储引擎

Percona 的 XTRDB 是基于 InnoDB 的一个改进版本。XtraDB 可以作为InnoDB 的一个完全的替代产品。

PBXT 支持引擎级别的复制，外键约束，对 SSD 的支持较好，被 MariaDB 所包含。

TokuDB 使用一种新的叫作分行书（Fractal Trees）的索引数据结构。TokuDB 是缓存无关的，因此即使其大小超过内存性能也不会下降，也就没有内存生命周期和碎片的问题。TokuDB 是种大数据存储引擎，因为其拥有很高的压缩比，可以在很大的数据量上创建大量索引。

RethinkDB 最初是为 SSD 设计的，和 PBXT 差不多。

### 选择合适的存储引擎

除非必须使用 InnoDB 不具备的特性而不能妥协，否则应该使用 InnoDB。

实际上，OLTP 的场景下使用 InnoDB，OLAP 场景，使用大数据框架来分析，已经成为了大多数互联网公司的标配场景。

不要轻易认定“MyISAM 比 InnoDB”之类的经验之谈。在很多已知场景下，InnoDB 的速度是 MyISAM 望尘莫及的，特别是能够使用聚簇索引查询，或者所访问的数据都可以放入内存中的应用。

### 转换表的存储引擎

#### ALTER TABLE

```SQL
ALTER TABLE mytable ENGINE = InnoDB;
```

这个操作会执行很长时间，MySQL 会把原表复制到新表中（这种新表被重新组织过，可以消除空洞）。在复制的过程中会消耗系统所有的 I/O 能力，而且表上会加读锁（**变成了 READ ONLY 的表，算是一种半停机的设置**）。

如果转换表的存储引擎，将会失去和原引擎相关的所有特性。一张表切换两次不同的引擎，可能导致外键都丢失。

#### EXPORT 和 IMPORT

可以使用 mysqldump 把表导出，然后修改 CREATE TABLE 的 engine 选项，注意同时修改表名，因为同一个 db 里不能存在相同的表名。

#### CREATE 和 SELECT

```SQL
CREATE TABLE innodb_table LIKE myisam_table;
ALTER TABLE innodb_table ENGINE=innodb;
INSERT INTO innodb_table SELECT * FROM myisam_table;
```

如果数据量不大的话，这样做很好；否则需要考虑分批处理，因为这样会产生过多的 undo。

可以考虑使用 Percona Toolkit 提供的 pt-online-schema-change 的工具。

## MySQL Timeline

5.5 版本的 MySQL 是史上质量最高的版本。体现了 Oracle 收购了 MySQL AB 以后对产品的关注。

## 总结

虽然有很多不同的插件 API，但存储引擎 API 还是最重要的。如果能理解 MySQL 在存储引擎和服务层之间处理查询时如何通过 API 来回交互，就能抓住 MySQL 基础架构的精髓。

**对 InnoDB 而言，一切操作都是事务。**

Oracle 一开始收购了 InnoDB，而后收购了 MySQL，最终导致了两者的融合。

# MySQl 基准测试

基准测试（benchmark）是 MySQL 新手和专家都需要掌握的一项基本技能。简单地说，基准测试是针对系统设计的一种压力测试。本章讲讨论基准测试的重要性、策略和工具。我们将特别讨论一下 sysbench，这是一款非常优秀的 MySQL 基准测试工具。

## 为什么要做基准测试

基准测试是唯一有效的、可以学习系统在给定的工作负载下会发生什么的方法。

基准测试的问题是这不是真实压力的测试，真实压力不可预期而且变化多端。测试工具的局限会影响结果的有效性。

使用基准测试对容量的余量进行规划，也不能简单地把基准测试里得到的 tps 增长看作容量的增长。

## 基准测试的策略

对系统进行测试，即 full-stack。单独测试 MySQL，即 single-component。
尽量做 full-stack 测试，因为：
- 用户关注的是整个应用的性能
- MySQL 并非总是应用的瓶颈，如何揭示瓶颈？
- 只有对应用做整体测试，才能发现各部分之间的缓存带来的影响。
- 正义应用的继承测试更真实

尽量使用生产真实数据的拷贝。

### 测试何种指标

#### 吞吐量（throughput）

单位时间能够处理的事务数，是最重要的需要关注指标。

#### 响应时间（response time）

因为应用本身的响应时间本身是受各种因素影响而波动的，所以大部分情况下关注 top percentile 90 之类的指标即可。可以用图表来关注这些指标。

#### 并发性（concurrency）

MySQL 的并发性不同于应用的并发性。应用的并发性通常指可以同时存在多少个会话，MySQL 的高并发则关注到底可以同时存在多少个数据库连接。很多时候并发性测试并不是寻找某个指标，而是看特定的并发性的前提下（如 128 个 server 线程），到底能够达到多大的 tps 和 rt。

#### 可扩展性（scalability）

在业务压力变化的情况下，可以测量增大系统的业务压力（或者提供更好的软硬件配置），吞吐量是不是也能线性增加（即是不是可以直接 scale up）。

大部分系统通常不能线性增加性能。

## 基准测试方法

应该避免一些常见的错误：

 - 使用真实数据的子集而不是全集。
 - 使用错误的数据分布。
 - 使用不真实的分布参数。
 - 在多用户的场景中，只做单用户的测试。
 - 在单服务器上测试分布式应用-同样地，不要用单线程来测试多线程应用。
 - 与真实用户行为不匹配。
 - 反复执行同一个查询。
 - 没有检查错误。
 - 忽略了系统预热。
 - 使用默认的服务器配置。
 - 测试时间太短。
 
测试要掌握业务的全貌，应该关注：
 - 注意 normal case 的分布，注意这些分布肯定不是均匀分布，所以真实的差异性流量是很必须的，这也导入了 corner case。
 - 如果流量和身份有关，则应该注意流量构成的差异。
 - 应该注意错误日志。

### 设计和规划基准测试

对于 OLTP 型业务，可以考虑 TPC-C；对于 OLAP 和即席查询的业务，可以考虑 TPC-H。

应该写下详细的测试规划，记录规划里的参数和预期的返回值。

### 基准测试应该运行多长时间

为了到系统稳定为止，应该运行尽可能长的时间。

### 获取系统的性能和状态

要定期地快速采样整个系统的性能快照（类似 JMX/top 方案，把系统的性能的涨落寻找出来）。

### 获得准确的测试结果

对 IO 密集型（IO-Bound）应用，不要采用 CPU 密集型（CPU-Bound）应用的测试标准。

确认测试结果是否重复，每次重新测试之前要确保系统的状态是否是一致。有必要的话要重启系统。

如果测试以前要改数据或者 schema，要注意用快照还原数据库。插入不同数量级的数据造成的磁盘碎片度和在磁盘上的分布肯定不同。一个确认磁盘数据的分布尽可能一致的方法是，每次都进行快速格式化并进行磁盘分区复制。

基于默认的配置进行测试通常没有意义，因为默认配置是基于消耗很少内存的极小应用的。

如果测试中出现异常数据，不要轻易地当作坏数据点进行丢弃。

### 运行基准测试并分析结果

要把“数字”变成“知识”。

### 绘图的重要性

考虑使用 gnuplot。

## 基准测试工具

### 集成测试工具

 - ab 最简单
 - http_load
 - JMeter 复杂很多，但对集成测试已经够用
 - 列表项
 
### 单组件式测试工具
 - mysqlslap 随着 MySQL 本身发布，可以根据 schema 生成 SELECT 语句，测试可以执行并发连接数，并指定 SQL 语句。
 - sql-bench 单线程测试，自带测试用例。
 - Super Smack
 - Database Test Suite
 - Percona's TPCC-MySQL Tool
 - sysbench **全功能测试工具**，它可以测试 cpu 性能（通过计算素数），磁盘 io 性能（通过模拟文件读写），db 性能（只要指定好 db 的文件夹和数据库）。

# 服务器性能剖析

测量服务器的时间花在哪里的工具是性能剖析技术。

应该抱有空杯心态，抛掉一些对性能的常见误解。

## 性能优化定义

对性能的定义有很多种，如吞吐量、响应（延迟）时间等**。原则一、性能即响应时间（Response Time）。**我们可以简单地采用一种方案来定义提升性能，就是看特定的工作负载下，降低响应（延迟 latency）时间。吞吐量比响应时间更容易测量，但测量响应时间更容易让我们的系统得到优化。

资源是用来消耗的。纯粹地降低资源的消耗不一定就能提高性能。高版本的 InnoDB 有更多的 CPU 利用率，并不是它性能变差了，可能反而性能变好了（CMS、G1 等 JVM 垃圾收集器同理）。

如果降低响应时间，得到的一个副产品就是系统的吞吐量提升了（通常，工作线程的可复性用变高了）。

**原则二、无法测量就无法有效地优化。**不要把时间花在修改东西上，应该把时间花在测量响应时间上（实际上修改东西也需要反复测试，盲目地修改等于盲目地反复测试，是一个线性复杂度的工程师时间浪费）。如果通过测量没有得到答案，那么要么测量的方式错了，要么测量得不够完整。与其把 90% 的时间花在修改系统上，不如把 90% 的时间花在测量上。

完成一项任务的时间通常可以分为两个部分：执行时间和等待时间。执行时间的优化方法，是优化子任务的执行频率、效率和并行度。等待时间的优化方法则复杂得多，需要很强的诊断工具。

测量通常是错的，例如多数的测量不是全量采样，多数的测量也只是系统的间断快照，而不是连续的快照。重点是测量有多不准确。

### 通过性能剖析进行优化

profiler 的工作方式总是相似的：在任务启动时启动计时器，在任务结束时停止计时器，然后减去不同的时间得到响应时间。

响应时间的统计结果通常包括：

 - 排名
 - 调用次数
 - （平均）响应时间
  - 执行时间
  - 等待时间
 - （有可能的话）执行结果

很多时间我们既要做基于执行时间的分析，也要坐基于等待时间的分析。但很多时候系统本身不提供很细致的内部测量点，所以我们并不能真的分析出一个响应时间内部，执行时间占多少，等待时间占多少。例如，我们并不一定知道，一个 sql 执行的时候，磁盘 io 的等待时间是多少。
   
### 理解性能剖析

只理解总计和平均值，会缺失很多信息。如：

 - 值得优化的查询（worthwhile query）：如果一个优化花了 1000 美元，却没有带来任何业务收益。其实等于做了一个 1000 美元的逆优化。
 - 异常情况：即使没有做过 profiling，也有些问题需要解决-当然如果有办法做全链路跟踪，没有 profiling 的死角的话，可以不考虑这个问题。
 - 未知的未知（unknown-unknown，拉姆斯菲尔德的笑话）：工具总有局限性，只能在一定精度内说明问题。
 - 被掩藏的细节：平均值不能说明问题。我们更多地需要直方图、百分比、标准差等等工具。
 
## 对应用程序进行剖析

**对性能的剖析建议还是自上而下进行。**这样可以追踪用户发起到服务器响应的整个流程。

性能瓶颈可能有很多影响因素：

 - 外部资源：比如调用了外部的 web 服务或者搜索引擎。
 - 应用需要大量时间处理的数据，比如分析一个超大的 xml 文件（或者查询一张超大的表并且返回结果也超大）。
 - 在循环中执行昂贵的操作，比如滥用正则表达式。
 - 使用低效的算法。
 
性能剖析会让系统变慢吗？局部来看，会。因为性能剖析总有开销（例如，Visual Studio 构建出的程序有 debug 的版本和 release 版本，debug 的版本里带有测量点，因此更慢一些）。全局来看，不会，因为性能剖析最终会让我们设计出更快的程序。

好的监控工具应该可以全天候测量应用程序的性能（在任何时间、任何环境）。

MySQL 企业监控器可以提供查询的性能。通常这类工具不是在库里实现（如美团的 zebra 里的内部打点），就是在代理层实现（如架设一个 MySQL proxy，当然这本书的作者不建议这样做）。

## 剖析 MySQL 查询

### 剖析服务器查询

服务器端的剖析很有价值，因为在服务器端可以有效地审计效率低下的查询。

如果只是需要找出代价高的查询，可以使用慢查询日志（尽管 MySQL 提供了很多的的测量点）。

当代的 workbench 可以很方便地查看某个 server 的 status，间接地提供 profiling 的功能。

#### 捕获 MySQL 的查询到日志文件中

MySQL 的慢查询的日志精度最高、开销最低。性能开销可以忽略不计，但对硬盘的大小有要求，这要求我们打开 log rotation 工具。

MySQL 同样支持通用查询日志（general query log），但对性能剖析没有什么时机作用。

如果因为某些原因，无法在服务器上记录查询（也就是看不到慢查询日志），那么还有两种替代方案：

 - SHOW FULL PROCESSLIST。查看慢查询、慢事务，进而 kill 查询、kill 事务。可以考虑使用 pt-query-digest。
 - 通过 tcp 抓包，然后解析。可以考虑使用 tcp-dum + pt-query-digest。
 
### 分析单条查询

三种方法，show status、show profile 和检查慢查询日志的条目。

#### show profile

```bash
-- 全局开启性能剖析
set profiling = 1
-- 查看各个查询的性能剖析
show profiles
```

show profiles 其实是一种查表的方案。

#### show status

show status 其实是显示一组计数器，既包括全局级别（global）的计数器，也包括会话级别（session）的计数器。

读懂这些计数器，需要读懂 innodb 的数据结构。

show status 其实也是一种查表的方案。

#### 使用慢查询日志

我们使用 explain 得到的结果是评估出来的查询性能结果。而使用慢查询日志得到的是实际执行的查询情况，可以很方便地读到实际的查询结果。explain 无法解释系统发生抖动，而 slow query 却可以。

使用特殊的工具，如 pt-query-digest，可以把它转化为查表的形式。

#### 使用 performance schema

另一种正在快速开发中，代表未来发展方向的性能剖析方案。

还是一种查表的形式。

### 使用性能剖析

server profiling 和 query profiling 可能都可以给性能优化提供帮助。用户需要对服务器如何执行查询有较深的了解。剖析报告应该尽可能多地收集需要的信息，给出诊断问题的正确方向。

但也有很多时候我们无法得到可靠的优化建议，因为：

- 我们可能只关注了 server profiling 而忽略了query profiling。
- 我们可能测量的只是查询开始之前的计数器，而不是查询开售的数据。
- 可能备份正在执行
- 可能发生了某种类型的 lock contention 或者其他争用。

## 诊断间歇性问题

幻影问题，往往难以重现，而且需要观察几个月。乱枪打鸟式的乱试，或者随机修改服务器配置来试图侥幸地找到问题，是人之常情，却也是危险的。试错不仅浪费时间，而且可能有可能让问题变得更坏。

### 单条查询问题还是服务器问题

服务有整体变慢吗，还是只有单条查询变慢？

服务器的问题非常常见，特别是老版本的 MySQL 既不适合 SMP 服务器，又有一定的扩展性限制。通常升级新版本的 MySQL 可以解决如上问题，但一旦出现问题，需要对新版本的更复杂机制有所了解。

如何判断是单挑查询问题还是服务器问题？如果问题周期性地出现，那么可以在某次活动中观察到（比较常见），或者整页运行脚本收集数据，第二天来分析结果。

此外，还有三种常见技术：

#### 使用 SHOW GLOBAL STATUS

最好每秒执行一次，列出类似查表的数据，然后使用 awk 工具截取变化的变量，形成类似 jstat log之类的分段涨落数据。

#### 使用 SHOW PROCESSLIST

最好也可以频繁执行，列出类似查表的数据，它对线程、连接的统计有很好的效应。

如果 MySQL 版本较新，可以查询 INFORMATION_SCHEMA 的 PROCESSLIST表；或者使用 innotop 工具以较高频率刷新。

#### 使用查询日志（query log）

如果有必要，打开 long_query_time = 0 的标记，记录所有的查询。但这个配置需要重置所有连接才能全局生效（除非使用 percona 的版本，可以强制在不断开连接的前提下，自动刷新配置）。

### 捕获诊断数据

如何尽可能多地收集数据，而不是恰好搜集到问题出现时的数据（特别是很容易收集不到）？

我们至少需要：

1. 一个可靠而且实时的“触发器”，也就是能区分什么时候问题出现的方法。
2. 一个收集诊断数据的工具。

#### 诊断触发器

#### 需要收集什么样的数据


在 GNU/Linux 平台，可以考虑 oprofile、strace、tcpdump。如果MySQL 内部线程卡在一个地方很长时间，往往都有相同的堆栈跟踪信息。这时候可以先启动 gdb，然后 attach 到 mysqld 进程，将所有线程的堆栈都转储（dump）出来。可以使用`sort | uniq | sort`等命令来排序出总计最多的堆栈信息。

#### 解释结果数据

这一节细节太多，还是要读原文为准。

## 其他剖析工具

### 使用 USER_STATISTICS 表

如果我们执行如下语句，可以看到 MySQL Percona 的 InnoDB 内核里有一些内置表（最初由谷歌开发的）：

```
SHOW TABLES FROM INFORMATION_SCHEMA LIKE '%_STATISTICS'

CLIENT_STATISTICS
INDEX_STATISTICS
TABLE_STATISTICS
THREAD_STATISTICS
USER_STATISTICS
```

### 使用 strace

strace 是另一个可以拿来度量系统调用的时间。例子：

```
strace -cfp $(pidof mysqld)
```

## 总结

值得总结的东西还是前面提供的东西：

 - 定义性能最有效的方法是响应时间
 - 无法测量就无法优化
 - 测量的最佳开始点是应用程序，而不是数据库
 - 大多数系统无法完整地测量，测量有时候也会有错误的结果。
 - 完整的测量会产生大量需要分析的数据，所以需要用到剖析器。
 - 剖析是一种汇总信息，掩盖和丢弃了太多的细节。
 - 有两种消耗时间的操作：工作和等待。
 - 优化和提升是两回事。
 - 注意你的直觉，但应该只根据直觉来指导解决问题的思路，而不是用于确定的问题。**决策应当尽量基于数据而不是感觉**。
 
# Schema 与数据类型优化

良好的逻辑设计和物理设计是高性能的基石。反范式的设计（计数表、汇总表、索引表）可以加快某些类型的查询，也可以使另一些类型的查询变慢。比如添加计数表和汇总表是一种很好的查询优化方式。

通常，我们要做 normalization，有时候要做冗余设计。

## 选择优化的数据类型

 - 更小的通常会更好。通常更小的数据类型有更小的数据开销。
 - 简单就好。使用最适配的数据类型通常比使用某些 hacky 的数据类型要好。
 - 尽量避免 null。很多列的默认值都是 null（即使没有显式地指定 `default null`）。通常情况下指定 not null 意味着我们选择性地回避了 null 的陷阱。查询中允许为 null 的列，索引本身的结构会比较复杂，查询的结果有时候也会出现反直觉的设计。

`SHOW CREATE TABL`展示的是基本类型（的正式名称），而不是别名。

### 整数类型

整数（whole numer）包括：

- TINYINT 8 位
- SMALLINT 16 位
- MEDIUMINT 24 位
- INT 32 位
- BIGINT 64 位

整数类型有可选的 UNSIGNED 属性，表示不允许负值。有符号和无符号使用同样的存储空间，所以无符号数的取值范围更大。

### 实数类型

MySQL 支持不精确类型（ FLOAT 和 DOUBLE 浮点数，使用浮点运算进行近似计算），也支持精确类型（DECIMAL）。

浮点运算被 cpu 原生支持，所以性能更好。DECIMAL 的支持是被 MySQL 内部通过自身实现支持的。

存储财务数据时，应该尽量使用 DECIMAL 或者 BIGINT。

### 字符串类型

 VARCHAR  可以变换存储空间的长度（除非指定了 ROW_FORMAT=FIXED），所以通常会更加节省存储空间。**行总是存在数据页里面的**，varchar 如果扩容，会导致数据页分裂。CHAR 则总是定长的适合存储很短，定长或者近乎定长的字符串，如 MD5。
 
有 VARCHAR  就有 VARBINARY。二进制数据和字符串数据的区别在于字符串数据有字符集和校对规则。

### BLOB 和 TEXT 类型

BLOB 和 TEXT 在 MySQL 里单独存储为对象的。

使用 BLOB 和 TEXT 会有可能会导致磁盘临时表（disk temp table），有必要的话可以考虑内存临时表（heap temp table）。如果 EXPLAIN 执行计划的 Extra 列包含“ Using Tempory”，则说明这个查询使用了隐式临时表。

### 日期和时间类型

5.5 的 MySQL 的最小时间粒度是秒。

#### DATETIME

与时区无关，使用 8 字节存储。可以使用 ANSI 的标准时间定义格式，如“2020-01-01 00:00:00”。

#### TIMESTAMP

与时区有关，指的是 Unix 的描述（可以使用 FROM_UNIXTIME 函数转换为日期），使用 4 字节存储。

### BIT 

最好不要用，很难理解和处理

### 选择标识符

即 PK 列：
- 整数类型，整数通常是最好选择，而且可以使用 AUTO_INCREMENT。
- ENUM 和 SET 是糟糕的选择。
- 应该避免使用字符串类型，因为他们很消耗空间。MyISAM 通常使用压缩索引，这导致查询慢很多。
- 尽量少用随机字符串，如 MD5()、SHA1（）。因为这些函数生成的新值会分布在很大的空间内。这会导致一些 select 语句变得很慢，而且 INSERT 变得更慢，这会导致页分裂，磁盘随机访问。会导致缓存的局部性原理失效，因为冷热数据的空间分布太不均匀。这种方案的唯一好处是可以消除热点。

### 特殊数据类型

IP 地址类型与其用 VARCHAR，不如直接用整数存储。可以考虑用 INET_ATON() 或者 INET_NTOA()-但如果使用了 ORM 框架，这种方案反而会比较难用。

## MySQL schema 设计中的陷阱

- 太多的列：MySQL 的存储引擎 API 和 server 层之间有一个行缓冲区。太多的列会使得行缓冲区转换出关键的行消耗过多的 cpu。
- 太多的关联。EAV（实体-属性-值）是一种常见的糟糕设计模式。EAV 很容易导致自关联（self-join）。MySQL 限制关联不能超过 61 张表，最好的实践是在 12 张表里做关联。- 更好的实践是不要关联。
- 慎用枚举。增加枚举值要 alter table，会导致全表锁这样的阻塞操作。
- 慎用 set。问题和枚举差不多，而且和枚举一样会让业务代码复杂。
- 慎用 null- 但有时候用 magic number 不如 null，null 可以代表未知值。如 datetime 的“0000-00-00 00:00:00”。

## 范式和反范式

对任何给定的数据，通常都有很多种表示方法，从完全的范式化到完全的反范式化，以及两者的折中。在范式化的数据库中，每个事实数据会出现且只出现一次。相反，在反范式的数据库中，信息是冗余的，可能会存储在多个地方。

冗余会导致数据不准确-“一个人有两块表，他就永远不知道时间。”

### 范式的优点和缺点

优点：
- 通常性能更好
- 不容易有冗余引起的逻辑错误

缺点：
- 切范式会导致 join，join 可能性能不好 - 这在 ES 上表现得尤为明显。

### 反范式化的优点和缺点

如果有两张表 join 起来的成本很高，把它们合成一张宽表（用合表的方式实现 join），加上索引，可以显著提升相关的查询效率。

这个章节里举了一个例子，在同时使用 where 和 order by limit 索引，查询优化器有可能走 order by 的索引，而不是 where 的索引，这样做不是基于基势的二分查找，效率可能和全表扫描差不多。

接下来它举了一个优化的例子，把 where 和 order by 的两列写在一个联合索引里，这样不用回表就完成了查询和排序（甚至只在存储引擎层就可以这样做）。

### 混用范式和反范式

纯洁的范式和反范式只出现在实验室里（正如教学用的模式和架构只出现在课本上一样）。

最常见的反范式化数据是复制或者缓存，这些冗余的数据可以通过触发器级联更新，但更好的方案是选择不常被更新的列。很多时候为了排序的需要，我们需要把数据从一张表冗余到另一张表。

## 缓存表和汇总表

有时候提升性能最好的方法是在同一张表中保存衍生的冗余数据。然而，有时候也需要一张完全独立的汇总表或者缓存表（特别是为满足检索的需求时）。

我们指的缓存表是可以比较简单地从 schema 的其他表获取（但每次获取的速度比较慢）数据的表。

而汇总表则保存的是使用 GROUP BY 语句聚合数据的表。也有人使用术语“累积表”（Roll-Up Table）来称呼这些表。

以网站为例子。我们可以为网站准备一个计数器表，记录每个小时的发送消息数。虽然不能保证计数器 100% 精确，但比实时维护计数器精确得多。实时计算统计值总是很昂贵的操作，要么必须扫描表中的大部分数据，要么查询语句只能在某些特定的索引上才能有效运行，而这类索引一般会对 UPDATE 操作有影响。计算最活跃的用户或者最常见的“标签”是这种操作的典型例子。而缓存表则对优化搜索和检索查询语句很有效。

除此之外的优化方法还有：

 - 对缓存表使用不同的存储引擎
 - 把缓存表导入专门的搜索系统
 
在使用缓存表和汇总表时，必须决定是实时维护数据，还是定期重建-其实还要考虑是增量重建，还是全量重建，如果使用全量重建，整张表的存储碎片会少很多。

当重建汇总表和缓存表时，通常需要保证数据在操作时依然可用。这就需要通过影子表来实现，通常影子表的实现为：

```SQL
DROP TABLE IF EXISTS a_new, a_old;
CREATE TABLE a_new LIKE a;
-- 导入数据
-- 在一个事务里同时做替换，有可能触发一个长时间的阻塞操作。
RENAME TABLE a to a_old, a_new to a
```
这样 a_old 里还存留有老的数据，有问题可以很容易地进行快速回滚操作。

### 物化视图（MV - Materialized Views）

MySQL 不天然支持物化视图，SQL Server 和 Oracle 支持。MySQL 的解决方案是 Flexviews。

参考[《MySQL物化视图方案 FlexViews》][1]：

> Flexviews 是 MySQL 5.1 的存储过程解决方案，主要用来创建物化视图，支持表关联和大多数 MySQL 的聚合函数。
> 
> 物化视图 (MV - Materialized
> Views)在一个段中存储查询结果，并且能够在提交查询时将结果返回给用户，从而不再需要重新执行查询 —
> 在查询要执行几次时（这在数据仓库环境中非常常见），这是一个很大的好处。物化视图可以利用一个快速刷新机制从基础表中全部或增量刷新。

Flexviews 支持从 SQL 转换为 Flexviews 的 API 的调用，类似 MapReduce。它可以分析 binlog，增量而不是全量地分析数据。

### 计数器表

应用中经常需要计数，但在更新计数器时可能碰到并发问题。

计数器表的几种形态：

1. 只有一列的计数器表，每次更新的时候事务严格串行：`set count = count + 1`。这个语句不会有写丢失的问题，但多事务并发更新一行性能非常差。
2. 一行记录有两列，一列槽，一列计数器，每次更新的时候随机执行：`set count = count + 1 where slot = RAND() * 100`。这样可以一定程度提高性能，但查询真正的总数时，需要`select sum(count)`。
3. 可以加上日期 date 作为更高层的分区列。
4. 使表有 upsert 的能力（insert 可以用 ON DUPLICATE KEY 来来避免 integrity exception）：`INSERT INTO DAILY_HIT_COUNTER(day, slot, cnt) VALUES(CURRENT_DAY, RAND() * 100, 1) ON DUPLICATE KEY UPDATE cnt = cnt + 1`。


如果希望减少表的行数，以避免表变得太大，可以写一个周期执行的任务，合并所有的结果到 0 号槽，并且删除所有其他的槽：

```SQL
-- 这一行语句可以一个事务内汇总所有的数据
update daily_hit_counter as c
 inner join (
    -- 选择每一天的最小槽，且把 cnt 先汇总一下
    select day, sum(cnt) as cnt, min(slot) as mslot
    from daily_hit_counter
    group by day
 ) as x using day
 -- 因为上面汇总过了，所以这里清理所有槽
 -- 如果本槽等于最小槽，维持本槽的 count，否则设为 0
 set c.cnt = if(c.slot = x.mslot, x.cnt, 0),
 -- 如果本槽等于最小槽，设置本槽的槽为0，否则维持原状。
 c.slot = if(c.slot = x.mslot, 0, c.slot);
 
-- 第二个事务把非 min_slot 的数据都删掉
delete from daily_hit_counter where slot <> 0 and cnt = 0;
```

## 加快 ALTER TABLE 的速度

MySQL 的 ALTER TABLE 操作的性能对大表而言是个大问题。MySQL 执行大部分表结构操作的方法是用新的结构创建一个空表。从旧表中查出所有的数据插入新表，然后删除旧表。这样操作需要很长时间，而且很耗内存。

因此诞生了一种 online ddl 的方案。这些功能不需要在整个操作过程中锁表。

但一般而言，大部分 ALTER TABLE 操作会导致 MySQL 的服务中断（因为锁表）。

其基本思路有：

 - 在一个不提供服务的从库上执行 alter table 操作，然后和主库进行切换；
 - 影子拷贝（ghost 表），创建一张和原表无关的新表（需要考虑验证和同时插入的问题），然后在一个事务里通过重命名和删除表操作交换两张表。

大部分的改表工具是使用方法 2。

有时候直接 alter table 会导致大量的读和插入。但 alter column 会直接改 .frm 文件。

还有另一个巧妙变更 .frm 文件的方法：

 1. 创建一张有相同结构的空表，并进行锁需要的修改（例如增加 ENUM 常量）。
 2. 执行 FLUSH TABLES WITH READ LOCK。**这将会关闭所有正在使用的表，并且禁止任何表被打开**。
 3. （通过操作系统命令）交换 .frm 文件。
 4. 执行 UNLOCK TABLES 来释放第 2 步的读锁。

### 快速创建 MyISAM 索引

这个方法的中心思想是**通过排序创建索引，这样创建索引更快且更紧凑**-但现实中恐怕不会有很好的收益。

```SQL
ALTER TABLE tb DISABLE KEYS;
ALTER TABLE tb ENABLE KEYS;
```

如果有索引没有建好，可以用 REPAIR TABLE 来重建索引。

# 创建高性能的索引

索引（MySQL 中也叫作键（key））是存储引擎用于快速找到记录的一种数据结构。

## 索引基础

索引可以包含一个或多个列的值。如果索引包含多个列，那么列的顺序也十分重要。因为 MySQL 只能高效地使用索引的最左前缀列。

因为索引过于复杂，所以简单地使用 ORM 往往不能有效地利用索引。

### 索引的类型

在 MySQL 中，索引是在存储引擎层而不是服务器层实现的。所以不同的存储引擎实现的索引是不一样的。

#### B-Tree 索引

大多数存储引擎都支持 B-Tree 索引。但 InnoDB 使用 B+Tree 索引。

存储引擎以不同的方式使用 B-Tree 索引，性能也各有不同。MyISAM 使用前缀压缩技术使得索引更小，但 InnoDB 则按照原数据格式进行存储。再如 MyISAM 索引通过数据的物理位置引用被索引的行，而 InnoDB则根据主键引用被索引的行（寻址问题）。

 
 
  [1]: https://www.oschina.net/p/flexviews/
