---
title: 数据密集型应用系统设计 - Designing Data Intensive Applications
date: 2020-10-11 23:09:02
tags:
- 系统架构
---
数据密集（Data-Intensive）与计算密集（Compute-Intensive）是当今两大负载类型。前者以大数据为代表，后者以深度学习和 HPC 为主要代表。

谨以本书献给那些追逐梦想的人们。

# 前言

数据密集型应用要处理的瓶颈往往是数据的规模、数据的复杂度和数据产生与变化的速率；与之对应的是计算密集型应用，CPU 往往成为其瓶颈。

本书是关于数据处理系统及其相关技术的（NoSQL、消息队列、缓存、搜索引擎、批处理和流处理框架）。

每一种技术都基于一定的设计理念，而且只适用于特定的场景。

**不要过度优化。**

# 可靠、可扩展与可维护的应用系统

现在的典型系统架构已经很明确了，因为业界已经有成功的案例，对这些组件做了很好的抽象，我们只要做好拿来主义就行了。

## 可靠性（Reliability）

fault tolerance 和 resilience 是系统的容错的体现。

### 硬件故障

对于大型 IDC，即使磁盘的 MTTF 很高，磁盘数量大了以后，每天发生磁盘损坏也是正常的事情。

硬件容错的方案是制造冗余（冗余磁盘、冗余电源）。

软件容错是第二种方式。

### 软件错误

软件错误可以被认为是 bug。检查 bug 的方法就是不断地做契约检查、测试。

### 人为失误

运维错误是系统下线的首要原因。

常见的做法有：

 - 以最小出错的方式来设计系统。
 - 想办法分离最容易出错的地方、容易引发故障的接口。
 - 充分的测试。
 - 当出现人为错误时、提供快速恢复机制。
 - 设置详细而清晰的监控子系统，包括性能指标和错误率。
 - 推行管理流程并加以培训。

## 可扩展性（ Scalability）

如果系统以某种方式增长，我们应对增长的措施有哪些。

### 描述负载

#### Twitter 的例子

Twitter 的高扇出（fan-out）的结构：

2011 年时：
- 用户发送 tweet 可以 达到 12k request/sec
- 用户有 300 k request/sec 的 home timeline 的读请求

用户有不同的扇出结构，决定了他们的潜在写放大的系数。

对于 home timeline 的读，有两种方式可以获取所有内容：

- lazy 方案

这个方案是基础方案，基于 MySQL 的联表查询。

每次每个 follower 读取自己的 home timeline 时，首先 join 自己的 follows 表里的 followee（通过 user_id = follower_id），然后用 followee 去 join user 表（ 通过 followee_id = user_id 这一步其实可以省略），然后用 user 表去 join tweets（通过 user_id = sender_id）。

这种 join 方法可以通过 server side join 来优化，但本质上还是逐步联表。每次做联表查询的时候 join 一次。

如果有必要，这里还可以把 join 的结果缓存起来优化频繁刷新的场景。

这种方法的缺点是，读取大量数据时老老实实地联表查询过多，性能不好。

- eager 方案

这个方案是性能优化方案，基于动态创建的广播队列。

每次每个 followee 发送 tweet 时，会先插入数据到 tweet 表里，然后通过广播的方式把这个 tweet 插入到每个 follower 的一个总的 tweets 列表里。这个列表可以是数据库，也可以是缓存的 list，也可以是 mq 的 topic。因为 mq 的 topic 不适合多对多的生产者和消费者的映射关系，而且动态创建 topic 的成本也很高。缓存的 list（如 redis 的 list）的创建销毁成本很低，很适合这种场景。

这种方案的优点是比方案 1 性能高两个数量级，缺点是如果 fan-out 很大的话，广播的时间会非常长。

因此 Twitter 最后的解决方案是先对大多数 followee 的 tweets 采用方案 2，而对于 fanout 特别多的 followee 的 tweets 使用方案 1，用户最终看到的内容，始终是方案 2 和方案 1 延迟合并的结果。

这个例子可以应用在非常多的 OLAP 场景内：即对于大数据量的数据汇总查询，我们可以优先采取 eager write 或者 broadcast 的方法在写事务的时候插入汇总数据；然后对于 fan-out 特别高的数据，在查询的时候 lazy 查询。选择方案时，需要考虑的因素主要是写成本比较高，还是读成本比较高。如果全量写的不会被全量读，而写成本很高的话，不如用 lazy read ；如果读的场景很高，联表查询出现的比例很高，则适合 eager write。

### 描述性能

批处理系统更看重吞吐量，即每秒处理的记录数；而在线系统更看重响应时间，即客户端从发送请求到接收响应之间的时间差（response time = server side latency + communication overhead）。响应时间不是一个固定的数字，而是一个可度量的数字分布。

我们可以用平均值来说明一些问题，但更多的情况下关注分布，我们使用百分位数（percentile），如 p50、p90、p95、p99。亚马逊使用 p999 来定义起内部服务的响应时间标准。

定义 SLA 有助于我们确定我们的标准，我们要为最慢的响应（tail latencies 长尾效应）优化到什么地步（百分位越高，越难优化）。

排队延迟往往在百分数响应时间中影响很大。因为服务器并行处理的请求优先，正在处理的少数请求可能阻挡后续的请求。这被称为队头阻塞。做负载测试的时候不要**等待队头阻塞（无意中缩短队列长度）**，要尽可能多地发送请求。

实践中，总是会使用滑动窗口来持续监控性能变化。

在实践之中，最慢的响应，决定了用户的 RT。

针对特定级别负载设计的架构不太可能应付超出预设目标 10 倍的实际负载-引入 APM 监控非常重要。

在多台机器上分配负载被称为无共享架构。这种架构易于水平扩展。如果服务负载高度不可预测，则引入自动的弹性扩展是好的，否则手动扩展更能处理意外情况。

超大规模的系统往往针对特定应用而高度定制，很难有一种通用架构。背后取舍的因素很多，如数据读写量、复杂程度、存储量，响应时间要求。

对特定应用而言，通常我们要做出某些假设（在可用性、一致性上做假设，如单元化场景下的弱一致性假设），有所取舍，才能在我们需要获得进展的方面取得结果-我们应该只优化最频繁的操作，或其他亟需我们优化的操作。

**可扩展架构通常是从通用模块逐步构建而来，背后往往有规律可循。**本书将讨论通用模块和常见模式。

## 可维护性

软件的成本在于整个生命周期内持续的维护。而遗留系统总有其过期的原因，很难给出通用的优化建议。

可维护性可以被分为三个方面：

 - 可运维性：运维/运营/SRE 团队易于保持系统平稳。
 - 简单性：新的工程师能够轻松理解系统。
 - 可演化性：能够轻松对系统改进
 
### 可运维性

运维团队可能有很多操作，数据系统设计可以提供如下便利：

 - Observability
 - 文档
 
### 简单性

大泥球应用除了功能以外，还提供很多额外意外的复杂性。这种意外的复杂性是可以消除的-而不必减少功能。

消除复杂性最好的手段之一就是抽象。**抽象可以隐藏大量的细节**，而且**可以对外提供干净、易懂的接口。**

### 可演化性

易于修改的系统，易于演化。我们总是处在不断变化的需求中。

# 数据模型与查询语言

语言的边界就是世界的边界。-《逻辑哲学论》

大多数程序都是通过一层一层叠加数据模型的方式来构建的（如网络协议中不同层使用不同的包）。

不同的数据模型支持的操作不一样，有的操作很好，有的操作很不好-数据结构决定算法，数据结构加算法等于程序。精通一种数据模型需要很大功夫。

## 关系模型与文档模型

 Edgar Codd关系型数据库的核心用例最初是商业数据处理，曾经出现过网络模型和层次模型等不同的范式作为竞争对手，但最终关系模型成为最终的赢家。
 
在关系模型里，relation 最终被当作表，行即元组。
 
NoSQL 是关系模型的有力竞争者，最初出现在 Twitter tag 里。它用 schemaless 换取了表达能力的提升，sharding 和 replica 换取了 scalability 的提升。

NoSQL 对 OO 的编程语言的适配性更好。

Linkedin profile 的例子告诉我们，education 和 position 对 user 而言是多对一的关系，可以建模为单独的行，也可以建模为嵌套的文档-因此可以使用 json document 来标表示（这可以转化为 json tree），也可以用关系型数据库的 xml/json 类型来表达。但行业、地区等全局的常量数据，则比较适合用单独的表来存放，使用 id 来引用，而严重不适合冗余存放。

不变的业务 fk、物理 fk 适合冗余，而时间/状态则不适合冗余。冗余可以减少联表查询的复杂度，但也会增加 update 的难度。

IBM 的 IMS 是最初的层次模型，可以很好地处理一对多问题，但不能很好地处理多对多问题-这种困境近似于现在文档数据库遇到的困境。

网络模型的代表是 CODASYL。在 CODASYL 里面每层有多个父节点，因此实现了多对多。在这种模型里，外键是指针，指针不是外键。这种模型按照路径遍历非常麻烦，更新也非常麻烦。

而使用了关系型数据库后，查询优化器会根据索引和表间关系，来生成“访问路径”-也就是执行计划。查询优化器是是一个被持续优化的怪兽。

文档数据库是某种意义上的层次模型-父文档保存了子文档。

文档型数据库的优点：性能更好，模型更像是程序自己的数据结构，**适合一对多模型**。

关系型数据库则强在 join、**多对一和多对多的表达上**。


