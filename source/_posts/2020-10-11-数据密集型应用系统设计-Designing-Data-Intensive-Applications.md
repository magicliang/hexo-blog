---
title: 数据密集型应用系统设计 - Designing Data Intensive Applications
date: 2020-10-11 23:09:02
tags:
- 系统架构
---
数据密集（Data-Intensive）与计算密集（Compute-Intensive）是当今两大负载类型。前者以大数据为代表，后者以深度学习和 HPC 为主要代表。

谨以本书献给那些追逐梦想的人们。

# 前言

数据密集型应用要处理的瓶颈往往是数据的规模、数据的复杂度和数据产生与变化的速率；与之对应的是计算密集型应用，CPU 往往成为其瓶颈。

本书是关于数据处理系统及其相关技术的（NoSQL、消息队列、缓存、搜索引擎、批处理和流处理框架）。

每一种技术都基于一定的设计理念，而且只适用于特定的场景。

**不要过度优化。**

# 可靠、可扩展与可维护的应用系统

现在的典型系统架构已经很明确了，因为业界已经有成功的案例，对这些组件做了很好的抽象，我们只要做好拿来主义就行了。

## 可靠性（Reliability）

fault tolerance 和 resilience 是系统的容错的体现。

### 硬件故障

对于大型 IDC，即使磁盘的 MTTF 很高，磁盘数量大了以后，每天发生磁盘损坏也是正常的事情。

硬件容错的方案是制造冗余（冗余磁盘、冗余电源）。

软件容错是第二种方式。

### 软件错误

软件错误可以被认为是 bug。检查 bug 的方法就是不断地做契约检查、测试。

### 人为失误

运维错误是系统下线的首要原因。

常见的做法有：

 - 以最小出错的方式来设计系统。
 - 想办法分离最容易出错的地方、容易引发故障的接口。
 - 充分的测试。
 - 当出现人为错误时、提供快速恢复机制。
 - 设置详细而清晰的监控子系统，包括性能指标和错误率。
 - 推行管理流程并加以培训。

## 可扩展性（ Scalability）

如果系统以某种方式增长，我们应对增长的措施有哪些。

### 描述负载

#### tweeter 的例子

Tweeter 的高扇出（fan-out）的结构：

2011 年时：
- 用户发送 tweet 可以 达到 12k request/sec
- 用户有 300 k request/sec 的 home timeline 的读请求

用户有不同的扇出结构，决定了他们的潜在写放大的系数。

对于 home timeline 的读，有两种方式可以获取所有内容：

- lazy 方案

这个方案是基础方案，基于 MySQL 的联表查询。

每次每个 follower 读取自己的 home timeline 时，首先 join 自己的 follows 表里的 followee（通过 user_id = follower_id），然后用 followee 去 join user 表（ 通过 followee_id = user_id 这一步其实可以省略），然后用 user 表去 join tweets（通过 user_id = sender_id）。

这种 join 方法可以通过 server side join 来优化，但本质上还是逐步联表。每次做联表查询的时候 join 一次。

如果有必要，这里还可以把 join 的结果缓存起来优化频繁刷新的场景。

这种方法的缺点是，读取大量数据时老老实实地联表查询过多，性能不好。

- eager 方案

这个方案是性能优化方案，基于动态创建的广播队列。

每次每个 followee 发送 tweet 时，会先插入数据到 tweet 表里，然后通过广播的方式把这个 tweet 插入到每个 follower 的一个总的 tweets 列表里。这个列表可以是数据库，也可以是缓存的 list，也可以是 mq 的 topic。因为 mq 的 topic 不适合多对多的生产者和消费者的映射关系，而且动态创建 topic 的成本也很高。缓存的 list（如 redis 的 list）的创建销毁成本很低，很适合这种场景。

这种方案的优点是比方案 1 性能高两个数量级，缺点是如果 fan-out 很大的话，广播的时间会非常长。

因此 Tweeter 最后的解决方案是先对大多数 followee 的 tweets 采用方案 2，而对于 fanout 特别多的 followee 的 tweets 使用方案 1，用户最终看到的内容，始终是方案 2 和方案 1 延迟合并的结果。

这个例子可以应用在非常多的 OLAP 场景内，即对于大数据量的数据汇总查询，我们可以优先采取 eager write 或者 broadcast 的方法在写事务的时候插入汇总数据；然后对于 fan-out 特别高的数据，在查询的时候 lazy 查询。选择方案时，需要考虑的因素主要是写成本比较高，还是读成本比较高。如果全量写的不会被全量读，而写成本很高的话，不如用 lazy read ；如果读的场景很高，联表查询出现的比例很高，则适合 eager write。


