---
title: Redis 笔记之十一-集群 Cluster
date: 2019-11-09 19:13:46
tags:
- Redis
---
# 背景
在 Redis Cluster 方案诞生以前，在 Redis 集群遇到单机资源和流量瓶颈时，有两种常见分布式解决方案：

- 客户端方案：需要自己处理分区逻辑、路由、故障转移。
- 代理方案：减轻了客户端的职责和压力，架构上的负担过重。

Redis Cluster 的出现，极大地降低了架构师的负担，解放了生产力。

# 数据分布

## 数据分布理论

|分区方式|特点|代表产品|
|:--:|:--:|:--:|
|哈希分区| 离散度好 数据分布业务无关 无法顺序访问| **KV型** Redis Cluster Cassandra Dynamo **Elastic Search**|
|顺序分区|离散度易倾斜 数据分布业务相关 可顺序访问| **表型 Bigtable** HBase Hypertable|

由于 Redis Cluster 采取哈希分区规则，常见的哈希分区规则有

### 节点取余分区

使用特定的数据，如 Redis 的键或用户 Id，再根据节点数量 N 使用公式：`hash(key)% N`（经典的双层 hash），用来决定数据映射到哪一个桶里。这种方案存在一个问题，当节点数量变化时，整个映射关系都要重新计算。

如果使用这种哈希方式，一开始就要规划好分区，保证可以支撑**未来一段时间的数据量**，扩容时可以天然采用翻倍扩容。

### 一致性哈希

一致性哈希（Distributed Hash Table）的实现思路是为系统中每个节点分配一个 token，范围一般在 0~2 power 32，这些 token 构成一个 hash 环。数据读写执行查找时，先 hash，然后顺时针（向大数方向）选最近一个 bucket。

![一致性散列.jpg](一致性散列.jpg)

一致性散列的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。但一致性哈希分区存在几个问题：

- 加减节点会造成哈希环中部分数据无法命中（取余分区一样存在这个问题），需要手动处理或者忽略这部分数据，因此一致性哈希常用于缓存场景。
- 当使用少量节点时，节点变化将大范围影响哈希环中数据映射，因此这种方式不适合少量数据节点的分布式方案。
- 普通的一致性哈希分区在增减节点时需要增加一倍或减去一般节点才能保证数据和负载的均衡。

### 虚拟槽分区

虚拟槽分区兼顾了取余分区和一致性哈希的优点，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。这个数一般远大于节点数，比如 Redis Cluster 的槽范围是 0 -16383。槽是集群内数据管理和迁移的基本单位。采用大范围的槽的目的是为了方便数据拆分和集群扩展，每个节点负责一定数量的槽。

## Redis 数据分区

slot = crc16(key) * 16383 - 注意这种取余的方法

每个节点负责维护一部分槽以及槽锁映射的键值数据。

![Redis Cluster 的槽位映射.jpg](Redis Cluster 的槽位映射.jpg)
