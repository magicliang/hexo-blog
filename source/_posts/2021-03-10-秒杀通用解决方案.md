---
title: 秒杀通用解决方案
date: 2021-03-10 22:30:13
tags:
- 数据库
---
# 秒杀的实质

## 秒杀的实质，是围绕库存管理展开的并发读写

如果架构设计里面包含商品系统，包含库存，秒杀就要解决库存热点行高并发读写问题。

秒杀的底线是：不能超卖。qty库存 ≥ qty卖出 && qty库存 - qty卖出 ≈ 0。
秒杀能够容忍的一些思路：渐进趋于一致，允许漏卖。

## 秒杀架构的特性

- 高性能：秒杀架构要承载的访问流量比平时高出许多倍，涉及大量的并发读和并发写，因此支持高并发访问非常关键。

- 一致性：秒杀活动中有限数量的商品在同一时刻被很多倍的请求同时扣减库存，在大并发更新的过程中要保证数据准确，不能发生超卖的问题（超卖，本来应该卖完下架的商品，在前台展示依然有库存，依然不停的被卖出），即库存是多少，理应卖出多少（qty库存 ≥ qty卖出 && qty库存 - qty卖出 ≈ 0）。

- 高可用：秒杀架构虽经多次打磨优化，但现实中总难免出现一些考虑不到的情况，要保证系统的高可用，还要设计一个兜底预案，以便在最坏的情况发生时仍能从容应对。

## 秒杀技术难点

1. 在有限的资源下，秒杀链路承载合理的最大流量。
2. 大并发下扣减库存准确，“一致性”中说到的“超卖”往往发生在该环节，减库存一般有下面几个方案：

- 下单减库存，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样基本不会出现超卖的情况。但是，有些人下完单可能并不会付款。
- 付款减库存，即买家下单后，并不立即减库存，而是等到用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为商品可能已经被其他人买走了。
- 预扣库存，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如10分钟），超过这个时间，库存将会自动释放，释放后其他买家可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款购买成功。



# 秒杀典型时序

1. 查询库存
2. 创建订单
3. 扣减库存（2 和 3 应该在一个事务里）
4. 更新订单
5. 付款

# 秒杀的 3 大挑战

## 超卖

2012 年的双11 产生了大量的超卖。事后复盘，大家发现系统中出现了未知的热点。

## 热点问题

缓存雪崩、缓存击穿，进而导致服务雪崩。

## 吞吐瓶颈

在高并发的情况下，整体吞吐水平会低于正常水平。

# 准则

## 热点发现

1. 根据业务场景，提前摸清热点数据。
2. 智能识别、动态散列，能够根据基线，自动识别热点，并扩容对应分片。

## 做好隔离

链路、机器、系统都要做好隔离、缓存和限流。不止考虑业务系统层面的限流和熔断，如果有必要，秒杀的资源要单独做好隔离。

## 动静分离

把用户请求的数据分为静态和动态数据。

## 基于时间分片削峰

- 答题
- 排队，同步变异步，从紧耦合变松耦合
- 读缓存（舍 c 得 a）

最终实现漏斗状的写，实现有效写入的数量足够小。

# 数据库的相关配置

说到数据库层秒杀优化，我们到底在做什么：加速事务执行的每个关键环节，降低事务耗时。

1. 库存分片，分而治之，提升热点行变更TPS，需要业务配合改造。
2. 降低行锁（row lock）持有时间，持锁时间长的SQL放在最后，提升并发。
3. 降低事务耗时，关闭deadlock detect、binlog group commit，和双1，加速事务。
4. 减少线程间切换，使用线程池Threadpool，提升并发效率，正在测试中。

# 现实案例分析

## 现实案例分析 1

热点商品的 sku，同步select for update 的锁定，在秒杀多个商品时冲突很严重，一种解决方案是使用 lua 的原子脚本来实现分布式锁，再异步锁定 sku 行，然后要加上对热点商品的限流，**在前端撞限流来减轻 db 的压力，提前让漏斗变小。**

乐观锁不适合高并发场景，因为重试很容易让系统过载。

悲观锁适合高并发场景-扣减库存的关键还是要排队，要看业务流程中是否允许异步化，允许就用 mq 排队，不允许就用悲观锁排队。

## 现实案例分析 2

用 nowait 或者 skip locked 来减少锁等待，避免阻塞和死锁。

每个 sql 的执行时间是 1.25ms，这一行被更新的 tps 就是 800。但实际上单行事务非常少，所以大事务晚释放锁会让行的并发性降低。

方法：

1. 合并 update，把热点 key 的更新语句在内存里 merge 一下。
2. 组提交：把双一写关掉，让 fsync 慢一点。
3. 删除多余的索引：需要考虑数据库的自治系统的建设。

秒杀是一种系统工程，需要业务理解数据库，关键还是在业务系统中做优化。

# 阿里和美团的解决方案

阿里使用 alisql 的内部排队和组提交事务的功能，大秒系统可以达到 8 万的 tps。其中排队指的是让请求的事务按照求锁顺序【使用信号量排队】获取锁，而不是将事务异步化，这可以让 MySQL 内核的死锁检测时间复杂度从 O(N*N)下降到 O(N)。

美团的解决有：架设一个 Redis 集群，通过 lua 脚本，实现一个在 redis 里的事务，扣减库存在 Redis 里实现，然后解析 aof 文件异步地真扣减库存，同时加上一个 mq（先写 redis 再写 mq），防止 Redis 丢失数据。mq 和 redis 对写操作做了建模，写操作带有版本，这样可以防止分布式环境下消息乱序和错漏重的问题。我猜这个版本可以是 seqNum，也可以是 行 version。这个方案被称作双通道冗余，在保证高可用的前提下逐步区域一致。aof 文件是一个纯异步复制的模式。这里使用的架构方案有点在本地做服务编排和 saga 的感觉。
