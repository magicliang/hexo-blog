---
title: 秒杀通用解决方案
date: 2021-03-10 22:30:13
tags:
- 数据库
---
# 秒杀的实质

秒杀的实质，是围绕库存管理展开的并发读写。

如果架构设计里面包含商品系统，包含库存，秒杀就要解决库存热点行高并发读写问题。

秒杀的底线是：不能超卖。qty库存 ≥ qty卖出 && qty库存 - qty卖出 ≈ 0。
秒杀能够容忍的一些思路：渐进趋于一致，允许漏卖。

# 秒杀典型时序

1. 查询库存
2. 创建订单
3. 扣减库存（2 和 3 应该在一个事务里）
4. 更新订单
5. 付款


# 秒杀的 3 大挑战

## 超卖

2012 年的双11 产生了大量的超卖。事后复盘，大家发现系统中出现了未知的热点。

## 热点问题

缓存雪崩、缓存击穿，进而导致服务雪崩。

## 吞吐瓶颈

在高并发的情况下，整体吞吐水平会低于正常水平。

# 准则

## 热点发现

1. 根据业务场景，提前摸清热点数据。
2. 智能识别、动态散列，能够根据基线，自动识别热点，并扩容对应分片。

## 做好隔离

链路、机器、系统都要做好隔离、缓存和限流。不止考虑业务系统层面的限流和熔断，如果有必要，秒杀的资源要单独做好隔离。

## 动静分离

把用户请求的数据分为静态和动态数据。

## 基于时间分片削峰

- 答题
- 排队，同步变异步，从紧耦合变松耦合
- 读缓存（舍 c 得 a）

最终实现漏斗状的写，实现有效写入的数量足够小。

# 现实案例分析 1

热点商品的 sku，同步select for update 的锁定，在秒杀多个商品时冲突很严重，一种解决方案是使用 lua 的原子脚本来实现分布式锁，再异步锁定 sku 行，然后要加上对热点商品的限流，**在前端撞限流来减轻 db 的压力，提前让漏斗变小。**

乐观锁不适合高并发场景，因为重试很容易让系统过载。

悲观锁适合高并发场景-扣减库存的关键还是要排队，要看业务流程中是否允许异步化，允许就用 mq 排队，不允许就用悲观锁排队。

# 现实案例分析 2

用 nowait 或者 skip locked 来减少锁等待，避免阻塞和死锁。

每个 sql 的执行时间是 1.25ms，这一行被更新的 tps 就是 800。但实际上单行事务非常少，所以大事务晚释放锁会让行的并发性降低。

方法：

1. 合并 update，把热点 key 的更新语句在内存里 merge 一下。
2. 组提交：把双一写关掉，让 fsync 慢一点。
3. 删除多余的索引：需要考虑数据库的自治系统的建设。

秒杀是一种系统工程，需要业务理解数据库，关键还是在业务系统中做优化。

# 阿里和美团的解决方案

阿里使用 alisql 的内部排队和组提交事务的功能，大秒系统可以达到 8 万的 tps。其中排队指的是让请求的事务按照求锁顺序【使用信号量排队】获取锁，而不是将事务异步化，这可以让 MySQL 内核的死锁检测时间复杂度从 O(N*N)下降到 O(N)。

美团的解决有：架设一个 Redis 集群，通过 lua 脚本，实现一个在 redis 里的事务，扣减库存在 Redis 里实现，然后解析 aof 文件异步地真扣减库存，同时加上一个 mq（先写 redis 再写 mq），防止 Redis 丢失数据。mq 和 redis 对写操作做了建模，写操作带有版本，这样可以防止分布式环境下消息乱序和错漏重的问题。我猜这个版本可以是 seqNum，也可以是 行 version。这个方案被称作双通道冗余，在保证高可用的前提下逐步区域一致。aof 文件是一个纯异步复制的模式。这里使用的架构方案有点在本地做服务编排和 saga 的感觉。
